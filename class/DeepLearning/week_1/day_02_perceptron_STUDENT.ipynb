{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Perceptron Coding Activity - Instructor solution\n",
    "\n",
    "Students need to code portions of the `PerceptronModel` Class:\n",
    "* `predict` function \n",
    "* `computeWeightUpdate` function\n",
    "\n",
    "Until the portions are coded, the perceptron is unable to learn and the training mechanism will stop after a maximum number of training steps\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def drawDecisionBoundary(model,X,y,title):\n",
    "    x1_min, x1_max = (X[:, 1].min() - 0.2), (X[:, 1].max() + 0.2)\n",
    "    x2_min, x2_max = (X[:, 2].min() - 0.2), (X[:, 2].max() + 0.2)\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.01),\n",
    "                     np.arange(x2_min, x2_max, 0.01))               \n",
    "    meshcount = xx1.ravel().shape[0]\n",
    "    f, ax = plt.subplots(figsize=(10, 8))\n",
    "    Z = model.predict(np.c_[np.ones(meshcount,),xx1.ravel(), xx2.ravel()])\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    ax.contourf(xx1,xx2, ~Z, alpha = 0.4, cmap=\"binary\")\n",
    "    #ax.scatter(X[:, 0], X[:, 1], c=-y, cmap=\"jet\", alpha=0.6)\n",
    "    c = np.array([[0, 0, 0], [0, 255, 0]])/255  #generates black and green colors\n",
    "    colors =np.dot(y,c[[1],:])+np.dot((1-y),c[[0],:])  #assigns colors per boolean label (0=black,1=green)\n",
    "    ax.scatter([X[:, 1]], [X[:, 2]],  cmap=\"jet\", alpha=0.6, color=colors)\n",
    "    ax.set_title(\"Decision boundary for \"+ title)\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "\n",
    "\n",
    "def displayResults(model,X,y,title):\n",
    "    drawDecisionBoundary(model,X,y,title)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(model.weightHistory[:,:].T)\n",
    "    plt.legend([\"bias\",\"w1\",\"w2\"])\n",
    "    plt.title(\"Weight History for \"+ title)\n",
    "    plt.xlabel(\"training step\")\n",
    "    plt.ylabel(\"weight\")\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(model.errorHistory)\n",
    "    plt.title(\"Error Count History for \" + title)\n",
    "    plt.legend([\"error count\"])\n",
    "    plt.xlabel(\"training step\")\n",
    "    plt.ylabel(\"Number of Errors\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# STUDENT CODE STEP\n",
    "\n",
    "## Perceptron Model Class definition\n",
    "\n",
    "Student code requried in the following functions\n",
    "\n",
    "* `predict` function which accepts a matrix of observations X, and using the weight matrix stroed in `self.w`, computes the result of activation of the perceptron\n",
    "* `computeWeightUpdate` function which computes the required change to the weights based on the error in predicitons, the current weights (`self.w`), and the learning rate (`self.alpha`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PerceptronModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.alpha = alpha  #learning rate for the perceptron\n",
    "        self.w = []   #to allow continued training with existing loaded weights\n",
    "        self.weightHistory = []  #to store the history of changing weights\n",
    "        self.errorHistory = [] #to store the history of changing errors\n",
    "        self.trainStepCount = 0\n",
    "        \n",
    "    def predict(self,X):\n",
    "        '''Given X, a matrix of observations (row = observation, column = feature),\n",
    "           return a column vector (np array of dimension N rows, 1 column) of predictions on X, one prediction per row in X\n",
    "           The activation function for the perceptron's prediction is assumed to be a step function at 0\n",
    "           such that for values less than or equal to zero, return zero\n",
    "           and for values greater than or equal to zero return 1\n",
    "        '''\n",
    "        yhat = np.zeros((X.shape[0],1))>0. #placeholder returns all False\n",
    "        # note that self.w contains the current weights of the model\n",
    "        # see if you can do this without using if-then statements\n",
    "        \n",
    "        ########## - INSERT STUDENT CODE HERE TO COMPUTE yhat #######\n",
    "        #######################################################################\n",
    "        \n",
    "        return yhat\n",
    "        \n",
    "    def computePerceptronError(self,X,D):\n",
    "        yhat = self.predict(X)\n",
    "        errorCount = np.sum(D!=yhat)\n",
    "        return errorCount    \n",
    "    \n",
    "    def computeWeightUpdate(self,x,D):\n",
    "        '''Given a single example (x) with desired target label D, \n",
    "        this should compute the weight updates on the perceptron weights\n",
    "        for one training step of the perceptron \n",
    "        (note - this function doesn't alter the model - it just computes the changes requried to the weights)\n",
    "        '''        \n",
    "        yhat=self.predict(x)\n",
    "        \n",
    "        deltaW = np.zeros(self.w.shape)  #placeholde for deltaW (changes to the weights)\n",
    "        \n",
    "        #compute the required change to to the weights using \n",
    "        \n",
    "        \n",
    "        ############ - INSERT STUDENT CODE HERE to compute deltaW - ###########\n",
    " \n",
    "\n",
    "        #######################################################################\n",
    "        return deltaW      \n",
    "        \n",
    "   \n",
    "    def fit(self,X,y,alpha=0.1, maxSteps = 200, errorTolerance = 0.):\n",
    "        '''\n",
    "        runs iterative single-observation training to train a perceptron -\n",
    "        equivalent to stochastic gradient descent\n",
    "        '''\n",
    "        obsCount = np.size(X,axis=0)\n",
    "        featureCount = np.size(X,axis=1)\n",
    "        pm = self\n",
    "        pm.alpha = alpha\n",
    "        #initialize random weights\n",
    "        weights = np.random.randn(featureCount,1)\n",
    "        pm.w = weights\n",
    "        pm.weightHistory = weights\n",
    "        error = pm.computePerceptronError(X,y)\n",
    "        pm.errorHistory = error\n",
    "        pm.trainStepCount = 0\n",
    "        #update model on single example at a time\n",
    "        while (error > errorTolerance) & (pm.trainStepCount < maxSteps):\n",
    "            obsIndex = np.random.choice(np.arange(obsCount))  #draw random example\n",
    "            x = X[obsIndex,:]\n",
    "            D = y[obsIndex]\n",
    "            weightUpdate = pm.computeWeightUpdate(x,D)\n",
    "            weights = weights + weightUpdate\n",
    "            error = pm.computePerceptronError(X,y) \n",
    "            pm.weightHistory = np.hstack((pm.weightHistory, weights))\n",
    "            pm.errorHistory = np.hstack((pm.errorHistory,error))\n",
    "            pm.w = weights\n",
    "            pm.trainStepCount+=1\n",
    "        return pm\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting up the datasets for AND, OR and XOR\n",
    "\n",
    "Next we build the datasets for these basic logic functions.  `X` is the truth table (as a design matrix with the first column of 1s to handle the bias term in the perceptron).  Labesl are stored in `yAND`, `yOR` and `yXOR`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#design matrix (note first member is bias term in design matrix)\n",
    "X = np.matrix([[1.,0.,0.],[1.,0.,1.],[1.,1.,0.],[1.,1.,1.]])\n",
    "\n",
    "#AND dataset labels \n",
    "yAND = np.matrix('0.;0.;0.;1.')\n",
    "#OR dataset labels\n",
    "yOR = np.matrix('0.;1.;1.;1.')\n",
    "#XOR dataset labels\n",
    "yXOR = np.matrix('0.;1.;1.;0.')\n",
    "\n",
    "print(X)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the perceptron for AND"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#train and return a model on the AND dataset\n",
    "#pmAND = trainPerceptron(X,yAND,alpha,maxSteps)\n",
    "\n",
    "#setup\n",
    "alpha = 0.1\n",
    "maxSteps = 200\n",
    "errorTolerance = 0.\n",
    "\n",
    "pmAND = PerceptronModel()\n",
    "pmAND.fit(X,yAND,alpha,maxSteps,errorTolerance)\n",
    "print(pmAND.predict(X))\n",
    "displayResults(pmAND,X,yAND,\"AND\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the perceptron for OR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#train and return a model on the OR dataset\n",
    "pmOR = PerceptronModel()\n",
    "\n",
    "pmOR.fit(X,yOR,alpha,maxSteps,errorTolerance)\n",
    "displayResults(pmOR,X,yOR,\"OR\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the perceptron for XOR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#train and return a model on the OR dataset\n",
    "pmXOR = PerceptronModel()\n",
    "pmXOR.fit(X,yXOR,alpha,maxSteps,errorTolerance)\n",
    "print(pmXOR.predict(X))\n",
    "displayResults(pmXOR,X,yXOR,\"XOR\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given that the XOR dataset runs for the max allowable iterations and fails to converge on a solution what should we do?"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}