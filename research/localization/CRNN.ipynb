{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "from librosa.effects import pitch_shift\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from librosa.feature import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "import tensorflow as tf\n",
    "import scipy.signal as signal\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.layers import Input, Conv1D, SeparableConv1D, MaxPooling1D, Flatten, Dense, Dropout, \\\n",
    "    BatchNormalization, Activation, LSTM\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "numFeat=40\n",
    "training_df=pd.read_csv(\"./range_training.csv\")\n",
    "y_train=training_df.loc[:,\"Range\"]\n",
    "x_train=training_df.loc[:,\"MFCC_0\":\"MFCC_39\"]\n",
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)\n",
    "mean = x_train.mean(axis=0)\n",
    "x_train -= mean\n",
    "std = x_train.std(axis=0)\n",
    "x_train /= std\n",
    "x_train=np.reshape(x_train, (len(x_train), numFeat, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "new_df= pd.DataFrame()\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A1R1P1\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A1R1P2\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A1R1P3\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A1R1P4\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A1R1P5\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A2R1P1\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A2R1P2\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A2R1P3\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A2R1P4\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A2R1P5\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A2R2P1\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A2R2P2\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A2R2P3\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A2R2P4\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "indiv_df=training_df.loc[training_df['Pass'] == \"A2R2P5\"]\n",
    "new_df= pd.concat([new_df, indiv_df])\n",
    "y_train=new_df.loc[:,\"Range\"]\n",
    "x_train=new_df.loc[:,\"MFCC_0\":\"MFCC_39\"]\n",
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)\n",
    "mean = x_train.mean(axis=0)\n",
    "x_train -= mean\n",
    "std = x_train.std(axis=0)\n",
    "x_train /= std\n",
    "x_train=np.reshape(x_train, (len(x_train), numFeat, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "trainFeatures, testFeatures, trainTargets, testTargets = train_test_split(x_train, y_train, test_size=0.9, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Attempt at a RCNN:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_1 (Conv1D)             (None, 19, 32)            96        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 19, 32)           128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 19, 32)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 9, 32)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_2 (Conv1D)             (None, 4, 32)             3072      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 4, 32)            128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 4, 32)             0         \n",
      "                                                                 \n",
      " conv_3 (Conv1D)             (None, 1, 32)             3072      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1, 32)            128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1, 32)             0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,665\n",
      "Trainable params: 29,473\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "211/211 [==============================] - 5s 8ms/step - loss: 11532.9219 - MSE: 11532.9219 - MAE: 73.2479 - val_loss: 4990.9136 - val_MSE: 4990.9136 - val_MAE: 48.9726 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 5303.1875 - MSE: 5303.1875 - MAE: 49.6169 - val_loss: 3454.3838 - val_MSE: 3454.3838 - val_MAE: 38.7278 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 4759.6060 - MSE: 4759.6060 - MAE: 46.6154 - val_loss: 3261.7710 - val_MSE: 3261.7710 - val_MAE: 37.1312 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 4530.5552 - MSE: 4530.5552 - MAE: 45.1769 - val_loss: 3310.4934 - val_MSE: 3310.4934 - val_MAE: 36.8277 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 4410.3232 - MSE: 4410.3232 - MAE: 44.3223 - val_loss: 3165.4788 - val_MSE: 3165.4788 - val_MAE: 36.6445 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 4041.6008 - MSE: 4041.6008 - MAE: 42.2075 - val_loss: 3117.3589 - val_MSE: 3117.3589 - val_MAE: 36.0609 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3940.8557 - MSE: 3940.8557 - MAE: 41.7278 - val_loss: 3109.8823 - val_MSE: 3109.8823 - val_MAE: 36.0587 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3721.7188 - MSE: 3721.7188 - MAE: 40.5254 - val_loss: 3191.9980 - val_MSE: 3191.9980 - val_MAE: 36.1966 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3565.0828 - MSE: 3565.0828 - MAE: 39.5566 - val_loss: 3090.6980 - val_MSE: 3090.6980 - val_MAE: 35.7479 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3580.6680 - MSE: 3580.6680 - MAE: 39.9464 - val_loss: 3174.2419 - val_MSE: 3174.2419 - val_MAE: 35.1940 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3332.1487 - MSE: 3332.1487 - MAE: 38.3952 - val_loss: 3077.9641 - val_MSE: 3077.9641 - val_MAE: 35.1317 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3143.9443 - MSE: 3143.9443 - MAE: 37.5353 - val_loss: 3107.2871 - val_MSE: 3107.2871 - val_MAE: 35.1005 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3142.6316 - MSE: 3142.6316 - MAE: 37.3720 - val_loss: 3072.5171 - val_MSE: 3072.5171 - val_MAE: 34.8104 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3006.0066 - MSE: 3006.0066 - MAE: 36.6345 - val_loss: 3235.5640 - val_MSE: 3235.5640 - val_MAE: 35.5657 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 2873.8066 - MSE: 2873.8066 - MAE: 35.9109 - val_loss: 3240.3735 - val_MSE: 3240.3735 - val_MAE: 35.9246 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 2934.6035 - MSE: 2934.6035 - MAE: 36.1235 - val_loss: 3288.7119 - val_MSE: 3288.7119 - val_MAE: 35.5046 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 2870.4580 - MSE: 2870.4580 - MAE: 35.4309 - val_loss: 3312.5403 - val_MSE: 3312.5403 - val_MAE: 36.0520 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 2671.1035 - MSE: 2671.1035 - MAE: 34.6097 - val_loss: 3385.4998 - val_MSE: 3385.4998 - val_MAE: 36.5252 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 2589.0029 - MSE: 2589.0029 - MAE: 34.0723 - val_loss: 3218.5254 - val_MSE: 3218.5254 - val_MAE: 35.2193 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 2641.0955 - MSE: 2641.0955 - MAE: 34.5500 - val_loss: 3361.4541 - val_MSE: 3361.4541 - val_MAE: 35.8202 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 2448.8291 - MSE: 2448.8291 - MAE: 33.4697 - val_loss: 3523.5068 - val_MSE: 3523.5068 - val_MAE: 36.7593 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 2398.8096 - MSE: 2398.8096 - MAE: 33.1205 - val_loss: 3246.1541 - val_MSE: 3246.1541 - val_MAE: 35.1362 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "208/211 [============================>.] - ETA: 0s - loss: 2359.7927 - MSE: 2359.7927 - MAE: 32.8118\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 2364.4209 - MSE: 2364.4209 - MAE: 32.8674 - val_loss: 3308.3059 - val_MSE: 3308.3059 - val_MAE: 35.4660 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 2068.6143 - MSE: 2068.6143 - MAE: 30.9052 - val_loss: 3267.0864 - val_MSE: 3267.0864 - val_MAE: 34.8693 - lr: 1.0000e-04\n",
      "Epoch 25/200\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 2036.3877 - MSE: 2036.3877 - MAE: 30.8230 - val_loss: 3289.8320 - val_MSE: 3289.8320 - val_MAE: 35.0929 - lr: 1.0000e-04\n",
      "Epoch 26/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 1945.2371 - MSE: 1945.2371 - MAE: 30.0240 - val_loss: 3348.9609 - val_MSE: 3348.9609 - val_MAE: 35.3971 - lr: 1.0000e-04\n",
      "Epoch 27/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 1903.7653 - MSE: 1903.7653 - MAE: 29.9973 - val_loss: 3328.2466 - val_MSE: 3328.2466 - val_MAE: 35.2664 - lr: 1.0000e-04\n",
      "Epoch 28/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 1886.7686 - MSE: 1886.7686 - MAE: 29.8102 - val_loss: 3286.8167 - val_MSE: 3286.8167 - val_MAE: 35.0183 - lr: 1.0000e-04\n",
      "Epoch 29/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 1862.7585 - MSE: 1862.7585 - MAE: 29.6483 - val_loss: 3344.6113 - val_MSE: 3344.6113 - val_MAE: 35.3176 - lr: 1.0000e-04\n",
      "Epoch 30/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 1845.9888 - MSE: 1845.9888 - MAE: 29.6736 - val_loss: 3351.0095 - val_MSE: 3351.0095 - val_MAE: 35.3258 - lr: 1.0000e-04\n",
      "Epoch 31/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 1880.9987 - MSE: 1880.9987 - MAE: 29.1120 - val_loss: 3387.1677 - val_MSE: 3387.1677 - val_MAE: 35.5104 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 1883.3611 - MSE: 1883.3611 - MAE: 29.5788 - val_loss: 3363.0791 - val_MSE: 3363.0791 - val_MAE: 35.4347 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "203/211 [===========================>..] - ETA: 0s - loss: 1852.7866 - MSE: 1852.7866 - MAE: 29.3433\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 1862.5409 - MSE: 1862.5409 - MAE: 29.4136 - val_loss: 3316.5515 - val_MSE: 3316.5515 - val_MAE: 35.0890 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 1744.1550 - MSE: 1744.1550 - MAE: 28.6037 - val_loss: 3329.3684 - val_MSE: 3329.3684 - val_MAE: 35.1801 - lr: 1.0000e-05\n",
      "Epoch 35/200\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 1800.3673 - MSE: 1800.3673 - MAE: 28.9814 - val_loss: 3331.5139 - val_MSE: 3331.5139 - val_MAE: 35.1739 - lr: 1.0000e-05\n",
      "Epoch 36/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 1807.3463 - MSE: 1807.3463 - MAE: 29.1255 - val_loss: 3322.3445 - val_MSE: 3322.3445 - val_MAE: 35.0513 - lr: 1.0000e-05\n",
      "Epoch 37/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 1789.4558 - MSE: 1789.4558 - MAE: 29.0779 - val_loss: 3327.9363 - val_MSE: 3327.9363 - val_MAE: 35.0831 - lr: 1.0000e-05\n",
      "Epoch 38/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 1755.6407 - MSE: 1755.6407 - MAE: 28.8036 - val_loss: 3325.9822 - val_MSE: 3325.9822 - val_MAE: 35.0279 - lr: 1.0000e-05\n",
      "Epoch 39/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 1830.8425 - MSE: 1830.8425 - MAE: 29.2272 - val_loss: 3323.7632 - val_MSE: 3323.7632 - val_MAE: 35.0058 - lr: 1.0000e-05\n",
      "Epoch 40/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 1790.7054 - MSE: 1790.7054 - MAE: 28.9014 - val_loss: 3315.1111 - val_MSE: 3315.1111 - val_MAE: 34.9351 - lr: 1.0000e-05\n",
      "Epoch 41/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 1773.5575 - MSE: 1773.5575 - MAE: 29.0527 - val_loss: 3314.6956 - val_MSE: 3314.6956 - val_MAE: 34.9498 - lr: 1.0000e-05\n",
      "Epoch 42/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 1767.1179 - MSE: 1767.1179 - MAE: 28.9928 - val_loss: 3325.0010 - val_MSE: 3325.0010 - val_MAE: 34.9582 - lr: 1.0000e-05\n",
      "Epoch 43/200\n",
      "211/211 [==============================] - ETA: 0s - loss: 1772.8900 - MSE: 1772.8900 - MAE: 29.0031\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 1772.8900 - MSE: 1772.8900 - MAE: 29.0031 - val_loss: 3330.6038 - val_MSE: 3330.6038 - val_MAE: 35.0058 - lr: 1.0000e-05\n",
      "Epoch 44/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 1741.4432 - MSE: 1741.4432 - MAE: 28.5975 - val_loss: 3333.0952 - val_MSE: 3333.0952 - val_MAE: 35.0263 - lr: 1.0000e-06\n",
      "Epoch 45/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 1766.8992 - MSE: 1766.8992 - MAE: 28.7155 - val_loss: 3332.9741 - val_MSE: 3332.9741 - val_MAE: 35.0234 - lr: 1.0000e-06\n",
      "Epoch 46/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 1771.4604 - MSE: 1771.4604 - MAE: 28.8468 - val_loss: 3333.9058 - val_MSE: 3333.9058 - val_MAE: 35.0289 - lr: 1.0000e-06\n",
      "Epoch 47/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 1787.1378 - MSE: 1787.1378 - MAE: 28.9766 - val_loss: 3333.8813 - val_MSE: 3333.8813 - val_MAE: 35.0274 - lr: 1.0000e-06\n",
      "Epoch 48/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 1813.7405 - MSE: 1813.7405 - MAE: 29.2557 - val_loss: 3334.3987 - val_MSE: 3334.3987 - val_MAE: 35.0350 - lr: 1.0000e-06\n",
      "Epoch 49/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 1745.9816 - MSE: 1745.9816 - MAE: 28.5662 - val_loss: 3333.1243 - val_MSE: 3333.1243 - val_MAE: 35.0243 - lr: 1.0000e-06\n",
      "Epoch 50/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 1864.8745 - MSE: 1864.8745 - MAE: 29.2608 - val_loss: 3333.6943 - val_MSE: 3333.6943 - val_MAE: 35.0256 - lr: 1.0000e-06\n",
      "Epoch 51/200\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 1762.0809 - MSE: 1762.0809 - MAE: 28.8491 - val_loss: 3334.3765 - val_MSE: 3334.3765 - val_MAE: 35.0294 - lr: 1.0000e-06\n",
      "Epoch 52/200\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 1740.9604 - MSE: 1740.9604 - MAE: 28.7110 - val_loss: 3334.8564 - val_MSE: 3334.8564 - val_MAE: 35.0319 - lr: 1.0000e-06\n",
      "Epoch 53/200\n",
      "211/211 [==============================] - ETA: 0s - loss: 1764.4202 - MSE: 1764.4202 - MAE: 28.5085\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 1764.4202 - MSE: 1764.4202 - MAE: 28.5085 - val_loss: 3334.8384 - val_MSE: 3334.8384 - val_MAE: 35.0312 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model =tf.keras.Sequential()\n",
    "model.add(Conv1D(filters=32,kernel_size=3, strides=2, use_bias=False, name='conv_1',input_shape=(numFeat,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(3, strides=2))\n",
    "model.add(Conv1D(filters=32,kernel_size=3, strides=2, use_bias=False,\n",
    "                         name='conv_2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(MaxPooling1D(64, strides=2))\n",
    "# hidden = MaxPooling1D(3, strides=2)(hidden)\n",
    "model.add(Conv1D(filters=32,kernel_size=3, strides=2, use_bias=False, name='conv_3'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(MaxPooling1D(3, strides=2))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(64, activation='relu', name='dense_1'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu', name='dense_2'))\n",
    "#model.add(LSTM(16))\n",
    "model.add(Dense(128, activation='relu', name='dense_3'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='linear', name='dense_4'))\n",
    "\n",
    "\n",
    "optimizer= tf.keras.optimizers.Adam() #method to prevent gradient clipping\n",
    "model.compile(loss='mse',optimizer=optimizer,metrics=['MSE','MAE'])\n",
    "\n",
    "\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                 verbose=1, patience=10, mode='auto')\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4,\n",
    "                          patience=40, mode='auto', restore_best_weights=True)\n",
    "model.summary()\n",
    "history = model.fit(trainFeatures, trainTargets,\n",
    "                      epochs=200,\n",
    "                      batch_size=32,\n",
    "                      shuffle=False,\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[reduceLR, early])\n",
    "# hidden = MaxPooling1D(3, strides=2)(hidden)\n",
    "#model.add(Flatten()) #this is where feature extraction turns to classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Attempt at a CNN:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 40, 1)]           0         \n",
      "                                                                 \n",
      " conv_1 (Conv1D)             (None, 19, 32)            96        \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 19, 32)           128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 19, 32)            0         \n",
      "                                                                 \n",
      " conv_2 (Conv1D)             (None, 9, 32)             3072      \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 9, 32)            128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 9, 32)             0         \n",
      "                                                                 \n",
      " conv_3 (Conv1D)             (None, 4, 32)             3072      \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 4, 32)            128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 4, 32)             0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 864)               111456    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 864)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 865       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,945\n",
      "Trainable params: 118,753\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 19s 7ms/step - loss: 7355.7563 - MSE: 7355.7563 - val_loss: 5468.0708 - val_MSE: 5468.0708 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 15s 7ms/step - loss: 6082.1909 - MSE: 6082.1909 - val_loss: 5242.2627 - val_MSE: 5242.2627 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 14s 7ms/step - loss: 5725.5063 - MSE: 5725.5063 - val_loss: 5180.5752 - val_MSE: 5180.5752 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 15s 7ms/step - loss: 5524.0195 - MSE: 5524.0195 - val_loss: 5005.3174 - val_MSE: 5005.3174 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 14s 7ms/step - loss: 5336.1382 - MSE: 5336.1382 - val_loss: 4967.6841 - val_MSE: 4967.6841 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 14s 7ms/step - loss: 5200.5107 - MSE: 5200.5107 - val_loss: 4930.0059 - val_MSE: 4930.0059 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 14s 7ms/step - loss: 5143.0493 - MSE: 5143.0493 - val_loss: 4824.1396 - val_MSE: 4824.1396 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 15s 7ms/step - loss: 5057.4556 - MSE: 5057.4556 - val_loss: 5083.4692 - val_MSE: 5083.4692 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 14s 7ms/step - loss: 5011.8960 - MSE: 5011.8960 - val_loss: 4937.2261 - val_MSE: 4937.2261 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 15s 7ms/step - loss: 4972.2603 - MSE: 4972.2603 - val_loss: 4681.1914 - val_MSE: 4681.1914 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 15s 7ms/step - loss: 4921.6646 - MSE: 4921.6646 - val_loss: 4609.1177 - val_MSE: 4609.1177 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 15s 7ms/step - loss: 4904.3579 - MSE: 4904.3579 - val_loss: 4722.5415 - val_MSE: 4722.5415 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 14s 7ms/step - loss: 4864.7256 - MSE: 4864.7256 - val_loss: 4671.8237 - val_MSE: 4671.8237 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 15s 7ms/step - loss: 4855.9482 - MSE: 4855.9482 - val_loss: 4588.4038 - val_MSE: 4588.4038 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 16s 7ms/step - loss: 4800.6885 - MSE: 4800.6885 - val_loss: 4531.5449 - val_MSE: 4531.5449 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 16s 8ms/step - loss: 4796.3862 - MSE: 4796.3862 - val_loss: 4540.4331 - val_MSE: 4540.4331 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 23s 10ms/step - loss: 4769.2744 - MSE: 4769.2744 - val_loss: 4515.2402 - val_MSE: 4515.2402 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 17s 8ms/step - loss: 4760.2134 - MSE: 4760.2134 - val_loss: 4499.3657 - val_MSE: 4499.3657 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 16s 7ms/step - loss: 4727.9438 - MSE: 4727.9438 - val_loss: 4503.9141 - val_MSE: 4503.9141 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 16s 7ms/step - loss: 4706.1074 - MSE: 4706.1074 - val_loss: 4516.3384 - val_MSE: 4516.3384 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 17s 8ms/step - loss: 4706.6138 - MSE: 4706.6138 - val_loss: 4520.3340 - val_MSE: 4520.3340 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 16s 8ms/step - loss: 4682.9873 - MSE: 4682.9873 - val_loss: 4440.4229 - val_MSE: 4440.4229 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 17s 8ms/step - loss: 4658.0635 - MSE: 4658.0635 - val_loss: 4547.6401 - val_MSE: 4547.6401 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 19s 9ms/step - loss: 4633.4126 - MSE: 4633.4126 - val_loss: 4442.3989 - val_MSE: 4442.3989 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "1549/2160 [====================>.........] - ETA: 4s - loss: 4581.9453 - MSE: 4581.9453"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [23]\u001B[0m, in \u001B[0;36m<cell line: 30>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     27\u001B[0m early \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, min_delta\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-4\u001B[39m,\n\u001B[0;32m     28\u001B[0m                           patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m, restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     29\u001B[0m network\u001B[38;5;241m.\u001B[39msummary()\n\u001B[1;32m---> 30\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainFeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainTargets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     32\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     33\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mreduceLR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1409\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1402\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1403\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1404\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1405\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1406\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1407\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1408\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1409\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1410\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1411\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2450\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2451\u001B[0m   (graph_function,\n\u001B[0;32m   2452\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2454\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1856\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1857\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1858\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1859\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1860\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1861\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1862\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1863\u001B[0m     args,\n\u001B[0;32m   1864\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1865\u001B[0m     executing_eagerly)\n\u001B[0;32m   1866\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    495\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    496\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 497\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    503\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    504\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    505\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    506\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    509\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    510\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(numFeat, 1))\n",
    "hidden = Conv1D(filters=32,kernel_size=3, strides=2, use_bias=False, name='conv_1')(inputs)\n",
    "hidden = BatchNormalization()(hidden)\n",
    "hidden = Activation('relu')(hidden)\n",
    "# hidden = MaxPooling1D(3, strides=2)(hidden)\n",
    "hidden = Conv1D(filters=32,kernel_size=3, strides=2, use_bias=False,\n",
    "                         name='conv_2')(hidden)\n",
    "hidden = BatchNormalization()(hidden)\n",
    "hidden = Activation('relu')(hidden)\n",
    "# hidden = MaxPooling1D(3, strides=2)(hidden)\n",
    "hidden = Conv1D(filters=32, kernel_size=3, strides=2, use_bias=False,\n",
    "                         name='conv_3')(hidden)\n",
    "hidden = BatchNormalization()(hidden)\n",
    "hidden = Activation('relu')(hidden)\n",
    "# hidden = MaxPooling1D(3, strides=2)(hidden)\n",
    "hidden = Flatten()(hidden) #this is where feature extraction turns to classification\n",
    "hidden = Dropout(0.5)(hidden)\n",
    "hidden = Dense(864, activation='relu', name='dense_1')(hidden)  # 896, 864, 928\n",
    "hidden = Dropout(0.5)(hidden)\n",
    "dist = Dense(1, activation='linear', name='dense_2')(hidden)\n",
    "network = Model(inputs=inputs, outputs=dist)\n",
    "\n",
    "optimizer= tf.keras.optimizers.Adam() #method to prevent gradient clipping\n",
    "network.compile(loss='mse',optimizer=optimizer,metrics=['MSE'])\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                 verbose=1, patience=10, mode='auto')\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4,\n",
    "                          patience=40, mode='auto', restore_best_weights=True)\n",
    "network.summary()\n",
    "history = network.fit(trainFeatures, trainTargets,\n",
    "                      epochs=200,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[reduceLR, early])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Attempt at a ANN:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 40, 200)           400       \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 40, 200)          800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_37 (Activation)  (None, 40, 200)           0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 40, 864)           173664    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 40, 600)           519000    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 40, 64)            38464     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 40, 64)            0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 40, 64)            4160      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 40, 64)            0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 40, 1)             65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 736,553\n",
      "Trainable params: 736,153\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 170s 77ms/step - loss: 12740.1836 - MSE: 12740.1738 - val_loss: 16896.2559 - val_MSE: 16896.2617 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "1891/2160 [=========================>....] - ETA: 17s - loss: 11620.5693 - MSE: 11620.5586"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [26]\u001B[0m, in \u001B[0;36m<cell line: 26>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     23\u001B[0m early \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, min_delta\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-4\u001B[39m,\n\u001B[0;32m     24\u001B[0m                           patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m, restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     25\u001B[0m model\u001B[38;5;241m.\u001B[39msummary()\n\u001B[1;32m---> 26\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainFeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainTargets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mreduceLR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1409\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1402\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1403\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1404\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1405\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1406\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1407\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1408\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1409\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1410\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1411\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2450\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2451\u001B[0m   (graph_function,\n\u001B[0;32m   2452\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2454\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1856\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1857\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1858\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1859\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1860\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1861\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1862\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1863\u001B[0m     args,\n\u001B[0;32m   1864\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1865\u001B[0m     executing_eagerly)\n\u001B[0;32m   1866\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    495\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    496\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 497\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    503\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    504\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    505\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    506\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    509\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    510\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model =tf.keras.Sequential()\n",
    "model.add(Dense(200,input_shape=(numFeat,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(864, activation='relu'))\n",
    "#model.add(MaxPooling1D(64, strides=2))\n",
    "# hidden = MaxPooling1D(3, strides=2)(hidden)\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(MaxPooling1D(3, strides=2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "optimizer= tf.keras.optimizers.Adam() #method to prevent gradient clipping\n",
    "model.compile(loss='mse',optimizer=optimizer,metrics=['MSE','MAE'])\n",
    "\n",
    "\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                 verbose=1, patience=10, mode='auto')\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4,\n",
    "                          patience=40, mode='auto', restore_best_weights=True)\n",
    "model.summary()\n",
    "history = model.fit(trainFeatures, trainTargets,\n",
    "                      epochs=200,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[reduceLR, early])\n",
    "# hidden = MaxPooling1D(3, strides=2)(hidden)\n",
    "#model.add(Flatten()) #this is where feature extraction turns to classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}