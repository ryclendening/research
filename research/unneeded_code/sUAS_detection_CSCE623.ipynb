{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "from librosa.effects import pitch_shift\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from librosa.feature import mfcc\n",
    "from sklearn import svm\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "features = []\n",
    "labels = []\n",
    "dataset_path: str = \"C:\\\\Users\\\\rclendening\\\\researchData\\\\RedVox_TrainingBinary_wYTVids\"\n",
    "data_dir = pathlib.Path(dataset_path)\n",
    "droneDict = {  # One hot encoding for labels probs should do it like I did below?\n",
    "    \"Drone\": [1, 0],\n",
    "    \"Noise\": [0, 1]\n",
    "}\n",
    "droneCountDict = {  # One hot encoding for labels\n",
    "    \"Drone\": 0,\n",
    "    \"Noise\": 1\n",
    "}\n",
    "\n",
    "dataCount = [0, 0]\n",
    "# drones = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "# filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "# filenames = tf.random.shuffle(filenames)\n",
    "# num_samples = len(filenames)\n",
    "# train_files = filenames\n",
    "# x = round((len(train_files) / 5))\n",
    "# train_files = train_files[:x]\n",
    "# print(\"Total num of samples: \", num_samples)\n",
    "# print(\"Number of examples per label:\", len(tf.io.gfile.listdir(str(data_dir / drones[0]))))\n",
    "# print(\"Example file tensor: \", filenames[0])\n",
    "# print(drones)\n",
    "train_files=[]\n",
    "for path, subdirs, files in os.walk(dataset_path):\n",
    "    for name in files:\n",
    "        train_files.append(os.path.join(path, name))\n",
    "# test_file = tf.io.read_file(\n",
    "#     \"C:\\\\Users\\\\rclendening\\\\researchData\\\\Training_Data_NM_RS\\\\IF1200\\\\d301sA1r01p0120210823_6.wav\")\n",
    "# test_audio, _ = tf.audio.decode_wav(contents=test_file)\n",
    "# test_audio.shape\n",
    "\n",
    "\n",
    "def split_audio(waveData, labelName, sampleFreq):\n",
    "    '''\n",
    "    Frames audio data and converts to feature space (MFCC)\n",
    "    :param waveData: waveData array of time-domain audio\n",
    "    :param frame_duration: Duration of frames desired\n",
    "    :param startTime: Start for each clip\n",
    "    :param sampleFreq: Sample Frequency (8Khz)\n",
    "    :param labelName: Name of label\n",
    "    @return list of features (ds), list of labels corresponding to feature dataset:\n",
    "    '''\n",
    "    # middle third of data\n",
    "    duration = waveData.shape[0]\n",
    "    startTime = np.round(duration / 3)\n",
    "    endTime = np.round(duration * 2 / 3)\n",
    "    waveDataSplit= waveData[int(startTime):int(endTime)]\n",
    "    features=MFCCCalc(waveDataSplit.squeeze(), sampleFreq)\n",
    "    dataCount[droneCountDict[labelName]] += features.shape[1]\n",
    "    label= [droneDict[labelName]] * features.shape[1]\n",
    "    return features, label\n",
    "\n",
    "def create_dataset(train_files):\n",
    "    '''\n",
    "    Creates feature dataset and label dataset.\n",
    "    @param train_files: EagerTensor of file paths.\n",
    "    @return list of features (ds), list of labels corresponding to feature dataset:\n",
    "    '''\n",
    "    i = 0\n",
    "    features = []\n",
    "    labels = []\n",
    "    for x in train_files:\n",
    "        #test_file = tf.io.read_file(x)\n",
    "        #test_audio, sampleRate = tf.audio.decode_wav(contents=test_file)\n",
    "        test_audio, sampleRate = librosa.load(x, sr=8000)\n",
    "        if min(np.asarray(test_audio)) != 0:\n",
    "            x = str(x)\n",
    "            label = x.split('\\\\')\n",
    "            label = label[5]\n",
    "            newData = test_audio[0: test_audio.shape[0] - test_audio.shape[0] % sampleRate]  # trim to nearest second\n",
    "            newFeats, newLabs = split_audio(newData, label, int(sampleRate))\n",
    "            features.extend(newFeats.transpose())\n",
    "            labels.extend(newLabs)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "def MFCCCalc(audioData, Fs):\n",
    "    '''\n",
    "    Converts decoded wav file to MFCC feature space\n",
    "    @param audioData: Numpy array of decoded audio wav file\n",
    "    @return MFCC coefficients\n",
    "    '''\n",
    "    #audioData=audioData.numpy()\n",
    "    data= audioData.astype(float)\n",
    "    #coefs = mfcc(data, sr=sampleRate, hop_length=2048)\n",
    "    coefs = mfcc(y=data, hop_length=2048,n_mfcc=40, sr=Fs)\n",
    "\n",
    "    return coefs\n",
    "\n",
    "def grabTrainingSamples(n, trainingData):\n",
    "    '''\n",
    "    Ensures even training set by grabbing an even amount of training samples from each class.\n",
    "    @param n: limiting class count\n",
    "    @param trainingData: trainingData list that includes both features and labels\n",
    "    @return MFCC coefficients\n",
    "    '''\n",
    "    droneCount=0\n",
    "    noiseCount=0\n",
    "    evenTrainingData = []\n",
    "    evenLabelData = []\n",
    "    for i in range(len(labels)):\n",
    "        lab = trainingData[i][1]\n",
    "        if lab == [1, 0] and droneCount < n:\n",
    "            droneCount += 1\n",
    "            evenTrainingData.append(trainingData[i][0])\n",
    "            evenLabelData.append(lab)\n",
    "        elif lab == [0,1] and noiseCount < n:\n",
    "            noiseCount += 1\n",
    "            evenTrainingData.append(trainingData[i][0])\n",
    "            evenLabelData.append(lab)\n",
    "    return evenTrainingData, evenLabelData\n",
    "\n",
    "Fs = 8000\n",
    "numFeat = 40 #COULD BE SOURCE OF ERROR\n",
    "features, labels = create_dataset(train_files)\n",
    "newSet = list(zip(features, labels))\n",
    "random.seed(42)\n",
    "random.shuffle(newSet)  # Ensure data is mixed together\n",
    "n = np.min(dataCount)  # Ensure data is symmetric (aka even amounts of training data for all classes)\n",
    "# features, labels = grabTrainingSamples(n, features, labels)\n",
    "features, labels = grabTrainingSamples(n, newSet)\n",
    "\n",
    "trainFeatures, testFeatures, trainTruth, testTruth = train_test_split(features, labels, test_size=0.8, random_state=42)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "newLabels=[]\n",
    "for x in trainTruth: #convert one hot to actual numbers\n",
    "    if x[0] == 1:\n",
    "        val=0\n",
    "    else:\n",
    "        val=1\n",
    "    newLabels.append(val)\n",
    "newTestLabels=[]\n",
    "for x in testTruth: #convert one hot to actual numbers\n",
    "    if x[0] == 1:\n",
    "        val=0\n",
    "    else:\n",
    "        val=1\n",
    "    newTestLabels.append(val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complex Model Evaluation (Linear SVM)\n",
    "\n",
    "This function performances' linear svm with cross validation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8402173913043478\n",
      "0.8356459676835012\n"
     ]
    }
   ],
   "source": [
    "scalar= StandardScaler()\n",
    "linear_model = svm.SVC(C=0.001,kernel='linear')\n",
    "pipeline= Pipeline([('transformer', scalar), ('estimator', linear_model)])\n",
    "cv = KFold(n_splits=5)\n",
    "scores= cross_val_score(pipeline,trainFeatures,newLabels,cv=cv)\n",
    "\n",
    "print(np.average(scores))\n",
    "pipeline.fit(trainFeatures,newLabels)\n",
    "print(pipeline.score(testFeatures,newTestLabels))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complex Model Evaluation (Poly SVM)\n",
    "\n",
    "This function performances' linear svm with cross validation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scalar= StandardScaler()\n",
    "poly_model = svm.SVC(kernel='poly')\n",
    "param_grid= {\n",
    "    'estimator__C':[1,10,100], 'estimator__gamma':[1,0.1,0.001,0.0001],'estimator__degree':[2,3,4]}\n",
    "pipeline= Pipeline([('transformer', scalar), ('estimator', poly_model)])\n",
    "cv = KFold(n_splits=4)\n",
    "search = GridSearchCV(pipeline, param_grid,refit=True,verbose=3, n_jobs=-1)\n",
    "print(search.fit(trainFeatures,newLabels))\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)\n",
    "scores= cross_val_score(pipeline,trainFeatures,newLabels,cv=cv)\n",
    "print(np.average(scores))\n",
    "pipeline.fit(trainFeatures,newLabels)\n",
    "print(pipeline.score(testFeatures,newTestLabels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('transformer', StandardScaler()), ('estimator', SVC(kernel='poly'))], 'verbose': False, 'transformer': StandardScaler(), 'estimator': SVC(kernel='poly'), 'transformer__copy': True, 'transformer__with_mean': True, 'transformer__with_std': True, 'estimator__C': 1.0, 'estimator__break_ties': False, 'estimator__cache_size': 200, 'estimator__class_weight': None, 'estimator__coef0': 0.0, 'estimator__decision_function_shape': 'ovr', 'estimator__degree': 3, 'estimator__gamma': 'scale', 'estimator__kernel': 'poly', 'estimator__max_iter': -1, 'estimator__probability': False, 'estimator__random_state': None, 'estimator__shrinking': True, 'estimator__tol': 0.001, 'estimator__verbose': False}\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.get_params())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complex Model Evaluation (RBF)\n",
    "\n",
    "This function performances' hyperparameter tuning of the RBF kernel for SVM. In TS which contains 80% of data, it achieves .90073 accuracy rate."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator__C': 100, 'estimator__gamma': 0.01}\n",
      "0.9008695652173913\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9007318310267372"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar= StandardScaler()\n",
    "model = svm.SVC(kernel='rbf')\n",
    "pipeline= Pipeline([('transformer', scalar), ('estimator', model)])\n",
    "cv = KFold(n_splits=10)\n",
    "param_grid= {\n",
    "    'estimator__C':[0.1,1,10,100], 'estimator__gamma':[1,0.1,0.01,0.001,0.0001]}\n",
    "\n",
    "search = GridSearchCV(pipeline, param_grid,refit=True,verbose=3, n_jobs=-1)\n",
    "print(search.fit(trainFeatures,newLabels))\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)\n",
    "newTestLabels=[]\n",
    "for x in testTruth: #convert one hot to actual numbers\n",
    "    if x[0] == 1:\n",
    "        val=0\n",
    "    else:\n",
    "        val=1\n",
    "    newTestLabels.append(val)\n",
    "search.score(testFeatures,newTestLabels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Model Evaluation: LDA/QDA\n",
    "\n",
    "The fact that LDA outperforms QDA suggests that there is more of a linear decision boundary within the dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82753623 0.84963768 0.83188406 0.83623188 0.85072464]\n",
      "[0.77681159 0.80217391 0.77826087 0.78985507 0.78985507]\n",
      "LDA Test Set Score 0.8367690747047315\n",
      "QDA Test Set Score 0.7816281428881965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "lda= LinearDiscriminantAnalysis()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "lda.fit(trainFeatures,newLabels)\n",
    "scores= cross_val_score(lda,trainFeatures,newLabels,cv=5)\n",
    "print(scores)\n",
    "qda.fit(trainFeatures,newLabels)\n",
    "scores= cross_val_score(qda,trainFeatures,newLabels,cv=5)\n",
    "print(scores)\n",
    "print(\"LDA Test Set Score\",lda.score(testFeatures,newTestLabels))\n",
    "print(\"QDA Test Set Score\",qda.score(testFeatures,newTestLabels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}