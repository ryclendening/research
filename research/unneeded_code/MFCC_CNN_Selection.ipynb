{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [49]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlibrosa\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrosa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meffects\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pitch_shift\n",
      "Input \u001B[1;32mIn [49]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlibrosa\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrosa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meffects\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pitch_shift\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "from librosa.effects import pitch_shift\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from librosa.feature import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "import tensorflow as tf\n",
    "import scipy.signal as signal\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.optimizers import adam_v2\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from keras.layers import Input, Conv1D, SeparableConv1D, MaxPooling1D, Flatten, Dense, Dropout, \\\n",
    "    BatchNormalization, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from librosa.effects import pitch_shift\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from librosa.feature import mfcc\n",
    "from sklearn import svm\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "features = []\n",
    "labels = []\n",
    "dataset_path: str = \"C:\\\\Users\\\\rclendening\\\\researchData\\\\RedVox_TrainingBinary_wYTVids\"\n",
    "data_dir = pathlib.Path(dataset_path)\n",
    "droneDict = {  # One hot encoding for labels probs should do it like I did below?\n",
    "    \"Drone\": [1, 0],\n",
    "    \"Noise\": [0, 1]\n",
    "}\n",
    "droneCountDict = {  # One hot encoding for labels\n",
    "    \"Noise\": 0,\n",
    "    \"Drone\": 1\n",
    "}\n",
    "\n",
    "dataCount = [0, 0]\n",
    "train_files=[]\n",
    "for path, subdirs, files in os.walk(dataset_path):\n",
    "    for name in files:\n",
    "        train_files.append(os.path.join(path, name))\n",
    "\n",
    "def split_audio(waveData, labelName, sampleFreq):\n",
    "    '''\n",
    "    Frames audio data and converts to feature space (MFCC)\n",
    "    :param waveData: waveData array of time-domain audio\n",
    "    :param frame_duration: Duration of frames desired\n",
    "    :param startTime: Start for each clip\n",
    "    :param sampleFreq: Sample Frequency (8Khz)\n",
    "    :param labelName: Name of label\n",
    "    @return list of features (ds), list of labels corresponding to feature dataset:\n",
    "    '''\n",
    "    # middle third of data\n",
    "    duration = waveData.shape[0]\n",
    "    startTime = np.round(duration / 3)\n",
    "    endTime = np.round(duration * 2 / 3)\n",
    "    waveDataSplit= waveData[int(startTime):int(endTime)]\n",
    "    features=MFCCCalc(waveDataSplit.squeeze(), sampleFreq)\n",
    "    dataCount[droneCountDict[labelName]] += features.shape[1]\n",
    "    #label= [droneDict[labelName]] * features.shape[1]\n",
    "    label= [droneCountDict[labelName]]*features.shape[1]\n",
    "    return features, label\n",
    "# def split_audio(waveData, labelName, sampleFreq,passName):\n",
    "#     '''\n",
    "#     Frames audio data and converts to feature space (MFCC)\n",
    "#     :param waveData: waveData array of time-domain audio\n",
    "#     :param frame_duration: Duration of frames desired\n",
    "#     :param startTime: Start for each clip\n",
    "#     :param sampleFreq: Sample Frequency (8Khz)\n",
    "#     :param labelName: Name of label\n",
    "#     @return list of features (ds), list of labels corresponding to feature dataset:\n",
    "#     '''\n",
    "#     if labelName == \"Drone\":\n",
    "#     # middle third of data\n",
    "#         #if  passName != \"A3R9\" and passName !=\"A3R1\":\n",
    "#         duration = waveData.shape[0]\n",
    "#         startTime = np.round(duration / 3)\n",
    "#         endTime = np.round(duration * 2 / 3)\n",
    "#         waveDataSplit= waveData[int(startTime):int(endTime)]\n",
    "#         features=MFCCCalc(waveDataSplit.squeeze(), sampleFreq)\n",
    "#         # elif passName== \"A3R9\":\n",
    "#         #     duration = waveData.shape[0]\n",
    "#         #     startTime = 0\n",
    "#         #     endTime = np.round(duration * 1 / 3)\n",
    "#         #     waveDataSplit= waveData[int(startTime):int(endTime)]\n",
    "#         #     features=MFCCCalc(waveDataSplit.squeeze(), sampleFreq)\n",
    "#         # elif passName== \"A3R1\":\n",
    "#         #     duration = waveData.shape[0]\n",
    "#         #     startTime = np.round(duration * 2/ 3)\n",
    "#         #     endTime = np.round(duration)\n",
    "#         #     waveDataSplit= waveData[int(startTime):int(endTime)]\n",
    "#         #     features=MFCCCalc(waveDataSplit.squeeze(), sampleFreq)\n",
    "#     elif labelName == \"Noise\":\n",
    "#         duration = waveData.shape[0]\n",
    "#         startTime = 0\n",
    "#         endTime = np.round(duration)\n",
    "#         waveDataSplit= waveData[int(startTime):int(endTime)]\n",
    "#         features=MFCCCalc(waveDataSplit.squeeze(), sampleFreq)\n",
    "#     dataCount[droneCountDict[labelName]] += features.shape[1]\n",
    "#     #label= [droneDict[labelName]] * features.shape[1]\n",
    "#     label= [droneCountDict[labelName]]*features.shape[1]\n",
    "#     return features, label\n",
    "\n",
    "def create_dataset(train_files):\n",
    "    '''\n",
    "    Creates feature dataset and label dataset.\n",
    "    @param train_files: EagerTensor of file paths.\n",
    "    @return list of features (ds), list of labels corresponding to feature dataset:\n",
    "    '''\n",
    "    i = 0\n",
    "    features = []\n",
    "    labels = []\n",
    "    for x in train_files:\n",
    "        #test_file = tf.io.read_file(x)\n",
    "        #test_audio, sampleRate = tf.audio.decode_wav(contents=test_file)\n",
    "        if str.split(x,\"\\\\\")[6][0] == 'y': #if youtube video mark yt as true\n",
    "            yt=1\n",
    "        else:\n",
    "            yt=0\n",
    "        test_audio, sampleRate = librosa.load(x, sr=8000)\n",
    "        if min(np.asarray(test_audio)) != 0 and len(test_audio)!=0:\n",
    "            x = str(x)\n",
    "            label = x.split('\\\\')\n",
    "            label = label[5]\n",
    "            passName=x.split('\\\\')[6][:4]\n",
    "            newData = test_audio[0: test_audio.shape[0] - test_audio.shape[0] % sampleRate]  # trim to nearest second\n",
    "            newFeats, newLabs = split_audio(newData, label, int(sampleRate))\n",
    "            features.extend(newFeats.transpose())\n",
    "            newLabs=list(zip(newLabs, np.ones(len(newLabs))*yt))\n",
    "            labels.extend(newLabs)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "def MFCCCalc(audioData, Fs):\n",
    "    '''\n",
    "    Converts decoded wav file to MFCC feature space\n",
    "    @param audioData: Numpy array of decoded audio wav file\n",
    "    @return MFCC coefficients\n",
    "    '''\n",
    "    #audioData=audioData.numpy()\n",
    "    data= audioData.astype(float)\n",
    "    #coefs = mfcc(data, sr=sampleRate, hop_length=2048)\n",
    "    coefs = mfcc(y=data, hop_length=1024,n_mfcc=40, sr=Fs)\n",
    "\n",
    "    return coefs\n",
    "\n",
    "def grabTrainingSamples(n, trainingData):\n",
    "    '''\n",
    "    Ensures even training set by grabbing an even amount of training samples from each class.\n",
    "    @param n: limiting class count\n",
    "    @param trainingData: trainingData list that includes both features and labels\n",
    "    @return MFCC coefficients\n",
    "    '''\n",
    "    droneCount=0\n",
    "    noiseCount=0\n",
    "    evenTrainingData = []\n",
    "    evenLabelData = []\n",
    "    for i in range(len(labels)):\n",
    "        lab = trainingData[i][1][0]\n",
    "        if lab == 1 and droneCount < n:\n",
    "            droneCount += 1\n",
    "            evenTrainingData.append(trainingData[i][0])\n",
    "            evenLabelData.append(trainingData[i][1])\n",
    "        elif lab == 0 and noiseCount < n:\n",
    "            noiseCount += 1\n",
    "            evenTrainingData.append(trainingData[i][0])\n",
    "            evenLabelData.append(trainingData[i][1])\n",
    "    return evenTrainingData, evenLabelData\n",
    "\n",
    "Fs = 8000\n",
    "numFeat = 40 #COULD BE SOURCE OF ERROR\n",
    "features, labels = create_dataset(train_files)\n",
    "newSet = list(zip(features, labels))\n",
    "random.seed(42)\n",
    "random.shuffle(newSet)  # Ensure data is mixed together\n",
    "n = np.min(dataCount)  # Ensure data is symmetric (aka even amounts of training data for all classes)\n",
    "# features, labels = grabTrainingSamples(n, features, labels)\n",
    "features, labels = grabTrainingSamples(n, newSet)\n",
    "#labels=to_categorical(np.array(labels)[:,0],num_classes=2)\n",
    "trainFeatures, testFeatures, trainTargets, testTargets = train_test_split(features, labels, test_size=0.20, random_state=42) #changed to speed up training\n",
    "trainTargets=np.array(trainTargets)\n",
    "trainFeatures = np.array(trainFeatures)\n",
    "testTargets=np.array(testTargets)\n",
    "testFeatures = np.array(testFeatures)\n",
    "# mean = trainFeatures.mean(axis=0)\n",
    "# trainFeatures -= mean\n",
    "# std = trainFeatures.std(axis=0)\n",
    "# trainFeatures /= std\n",
    "trainFeatures = np.reshape(trainFeatures,\n",
    "                           (len(trainFeatures), numFeat, 1))\n",
    "#testFeatures = np.asarray(testFeatures)\n",
    "# testFeatures -= mean\n",
    "# testFeatures /= std\n",
    "testFeatures = np.reshape(testFeatures, (len(testFeatures), numFeat, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([75322.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n            0., 75322.]),\n array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n <BarContainer object of 10 artists>)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.array(labels)[:,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CNNv1=tf.keras.Sequential()\n",
    "CNNv1.add(Input(shape=(numFeat, 1)))\n",
    "CNNv1.add(BatchNormalization())\n",
    "CNNv1.add(Conv1D(filters=32,kernel_size=3, strides=2, use_bias=False,padding='same', name='conv_1'))\n",
    "CNNv1.add(BatchNormalization())\n",
    "CNNv1.add(Activation('relu'))\n",
    "# hidden = MaxPooling1D(3, strides=2)(hidden)\n",
    "CNNv1.add(Conv1D(filters=32,kernel_size=3, strides=2, use_bias=False,padding='same', #was 32\n",
    "                         name='conv_2'))\n",
    "CNNv1.add(BatchNormalization())\n",
    "CNNv1.add(Activation('relu'))\n",
    "# hidden = MaxPooling1D(3, strides=2)(hidden)\n",
    "CNNv1.add(Conv1D(filters=32, kernel_size=3, strides=2,padding='same', use_bias=False, #was 32\n",
    "                         name='conv_3'))\n",
    "CNNv1.add(BatchNormalization())\n",
    "CNNv1.add(Activation('relu'))\n",
    "# hidden = MaxPooling1D(3, strides=2)(hidden)\n",
    "CNNv1.add(Flatten()) #this is where feature extraction turns to classification\n",
    "CNNv1.add(Dense(864, activation='relu', name='dense_1'))\n",
    "CNNv1.add(Dropout(0.5))\n",
    "CNNv1.add(Dense(1, activation='sigmoid', name='dense_2'))\n",
    "#dist = Dense(1, activation='sigmoid', name='dense_2')(hidden)\n",
    "CNNv1.summary()\n",
    "CNNv1.compile(optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'],)\n",
    "# Train classifier\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                 verbose=1, patience=10, mode='auto')\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4,\n",
    "                          patience=20, mode='auto', restore_best_weights=True)\n",
    "history = CNNv1.fit(trainFeatures, trainTargets[:,0],\n",
    "                      epochs=200,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[reduceLR, early])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Learning Curves')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.ylabel('Binary Crossentropy')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.show()\n",
    "print(CNNv1.evaluate(testFeatures,testTargets[:,0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions=CNNv1.predict(testFeatures)\n",
    "CNNv1.evaluate(testFeatures,testTargets[:,0])\n",
    "predictions=np.squeeze(predictions>0.5)\n",
    "print(recall_score(testTargets[:,0],predictions))\n",
    "print(precision_score(testTargets[:,0],predictions))\n",
    "print(f1_score(testTargets[:,0],predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from research.dataImporting import MLtools\n",
    "MLtools.save_model(CNNv1,\"1DCNN_PL_V1\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CNNv2=tf.keras.Sequential()\n",
    "CNNv2.add(Input(shape=(numFeat, 1)))\n",
    "CNNv2.add(BatchNormalization())\n",
    "CNNv2.add(Conv1D(filters=8,kernel_size=2, strides=1, use_bias=False,padding='same', name='conv_1'))\n",
    "CNNv2.add(BatchNormalization())\n",
    "CNNv2.add(Activation('relu'))\n",
    "# hidden = MaxPooling1D(3, strides=2)(hidden)\n",
    "CNNv2.add(Conv1D(filters=16,kernel_size=4, strides=2, use_bias=False,padding='same', #was 32\n",
    "                         name='conv_2'))\n",
    "CNNv2.add(BatchNormalization())\n",
    "CNNv2.add(Activation('relu'))\n",
    "# hidden = MaxPooling1D(3, strides=2)(hidden)\n",
    "CNNv2.add(Conv1D(filters=32, kernel_size=6, strides=2,padding='same', use_bias=False, #was 32\n",
    "                         name='conv_3'))\n",
    "CNNv2.add(BatchNormalization())\n",
    "CNNv2.add(Activation('relu'))\n",
    "# hidden = MaxPooling1D(3, strides=2)(hidden)\n",
    "CNNv2.add(Flatten()) #this is where feature extraction turns to classification\n",
    "CNNv2.add(Dense(512, activation='relu', name='dense_1'))\n",
    "CNNv2.add(Dropout(0.5))\n",
    "CNNv2.add(Dense(1, activation='sigmoid', name='dense_2'))\n",
    "#dist = Dense(1, activation='sigmoid', name='dense_2')(hidden)\n",
    "CNNv2.summary()\n",
    "CNNv2.compile(optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'],)\n",
    "# Train classifier\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                 verbose=1, patience=10, mode='auto')\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4,\n",
    "                          patience=20, mode='auto', restore_best_weights=True)\n",
    "history = CNNv2.fit(trainFeatures, trainTargets[:,0],\n",
    "                      epochs=200,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[reduceLR, early])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Learning Curves')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.ylabel('Binary Crossentropy')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.show()\n",
    "print(CNNv2.evaluate(testFeatures,testTargets[:,0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions=CNNv2.predict(testFeatures)\n",
    "CNNv2.evaluate(testFeatures,testTargets[:,0])\n",
    "predictions=np.squeeze(predictions>0.5)\n",
    "print(recall_score(testTargets[:,0],predictions))\n",
    "print(precision_score(testTargets[:,0],predictions))\n",
    "print(f1_score(testTargets[:,0],predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CNNv3=tf.keras.Sequential()\n",
    "CNNv3.add(Input(shape=(numFeat, 1)))\n",
    "CNNv3.add(BatchNormalization())\n",
    "CNNv3.add(Conv1D(filters=8,kernel_size=2, strides=1, use_bias=False,padding='same', name='conv_1'))\n",
    "CNNv3.add(BatchNormalization())\n",
    "CNNv3.add(Activation('leaky_relu'))\n",
    "CNNv3.add(Conv1D(filters=16,kernel_size=3, strides=1, use_bias=False,padding='same', #was 32\n",
    "                         name='conv_2'))\n",
    "CNNv3.add(BatchNormalization())\n",
    "CNNv3.add(Activation('leaky_relu'))\n",
    "CNNv3.add(Conv1D(filters=32, kernel_size=4, strides=2,padding='same', use_bias=False, #was 32\n",
    "                         name='conv_3'))\n",
    "CNNv3.add(BatchNormalization())\n",
    "CNNv3.add(Activation('leaky_relu'))\n",
    "CNNv3.add(Conv1D(filters=64, kernel_size=4, strides=2,padding='same', use_bias=False, #was 32\n",
    "                         name='conv_4'))\n",
    "CNNv3.add(BatchNormalization())\n",
    "CNNv3.add(Activation('leaky_relu'))\n",
    "CNNv3.add(Flatten()) #this is where feature extraction turns to classification\n",
    "CNNv3.add(Dropout(0.3))\n",
    "CNNv3.add(Dense(1024, activation='leaky_relu', name='dense_1'))\n",
    "CNNv3.add(Dropout(0.5))\n",
    "CNNv3.add(Dense(512, activation='leaky_relu', name='dense_2'))\n",
    "CNNv3.add(Dense(1, activation='sigmoid', name='dense_3'))\n",
    "#dist = Dense(1, activation='sigmoid', name='dense_2')(hidden)\n",
    "CNNv3.summary()\n",
    "CNNv3.compile(optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'],)\n",
    "# Train classifier\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                 verbose=1, patience=10, mode='auto')\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4,\n",
    "                          patience=20, mode='auto', restore_best_weights=True)\n",
    "history = CNNv3.fit(trainFeatures, trainTargets[:,0],\n",
    "                      epochs=200,\n",
    "                      batch_size=32,\n",
    "                      shuffle=True,\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[reduceLR, early])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Learning Curves')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.ylabel('Binary Crossentropy')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.show()\n",
    "print(CNNv3.evaluate(testFeatures,testTargets[:,0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions=CNNv3.predict(testFeatures)\n",
    "CNNv3.evaluate(testFeatures,testTargets[:,0])\n",
    "predictions=np.squeeze(predictions>0.5)\n",
    "print(\"Recall:\",recall_score(testTargets[:,0],predictions))\n",
    "print(\"P:\",precision_score(testTargets[:,0],predictions))\n",
    "print(\"f1:,\",f1_score(testTargets[:,0],predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from research.dataImporting import MLtools\n",
    "MLtools.save_model(CNNv3,\"1DCNN_PL_V3(final)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM Tuning,just gonna assume the hyper-parameters I tuned from before are still valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scalar= StandardScaler()\n",
    "model = svm.SVC(kernel='rbf',C=10,gamma=0.1)\n",
    "pipeline= Pipeline([('transformer', scalar), ('estimator', model)])\n",
    "trainFeaturesSVM = np.squeeze(trainFeatures)\n",
    "testFeaturesSVM = np.squeeze(testFeatures)\n",
    "# cv = KFold(n_splits=5)\n",
    "param_grid= {\n",
    "    'estimator__C':[10], 'estimator__gamma':[0.1]}\n",
    "print(pipeline.fit(trainFeaturesSVM,trainTargets[:,0]))\n",
    "pipeline.score(testFeaturesSVM,testTargets[:,0])\n",
    "search = GridSearchCV(pipeline, param_grid,refit=True,verbose=3, n_jobs=-1,cv=5)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline_preds=pipeline.predict(testFeaturesSVM)\n",
    "pipeline_preds=np.squeeze(pipeline_preds>0.5)\n",
    "print(\"Acc:\",accuracy_score(testTargets[:,0],pipeline_preds))\n",
    "print(\"Recall:\",recall_score(testTargets[:,0],pipeline_preds))\n",
    "print(\"P:\",precision_score(testTargets[:,0],pipeline_preds))\n",
    "print(\"f1:,\",f1_score(testTargets[:,0],pipeline_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [48]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cross_val_score\n\u001B[0;32m      2\u001B[0m scores\u001B[38;5;241m=\u001B[39mcross_val_score(pipeline,trainFeaturesSVM,trainTargets[:,\u001B[38;5;241m0\u001B[39m], cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n",
      "Input \u001B[1;32mIn [48]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cross_val_score\n\u001B[0;32m      2\u001B[0m scores\u001B[38;5;241m=\u001B[39mcross_val_score(pipeline,trainFeaturesSVM,trainTargets[:,\u001B[38;5;241m0\u001B[39m], cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores=cross_val_score(pipeline,trainFeaturesSVM,trainTargets[:,0], cv=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}