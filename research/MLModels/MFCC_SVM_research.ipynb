{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "from librosa.effects import pitch_shift\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from librosa.feature import mfcc\n",
    "from sklearn import svm\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "features = []\n",
    "labels = []\n",
    "dataset_path: str = \"C:\\\\Users\\\\rclendening\\\\researchData\\\\RedVox_TrainingBinary_wYTVids\"\n",
    "data_dir = pathlib.Path(dataset_path)\n",
    "droneDict = {  # One hot encoding for labels probs should do it like I did below?\n",
    "    \"Drone\": [1, 0],\n",
    "    \"Noise\": [0, 1]\n",
    "}\n",
    "droneCountDict = {  # One hot encoding for labels\n",
    "    \"Drone\": 0,\n",
    "    \"Noise\": 1\n",
    "}\n",
    "\n",
    "dataCount = [0, 0]\n",
    "# drones = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "# filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "# filenames = tf.random.shuffle(filenames)\n",
    "# num_samples = len(filenames)\n",
    "# train_files = filenames\n",
    "# x = round((len(train_files) / 5))\n",
    "# train_files = train_files[:x]\n",
    "# print(\"Total num of samples: \", num_samples)\n",
    "# print(\"Number of examples per label:\", len(tf.io.gfile.listdir(str(data_dir / drones[0]))))\n",
    "# print(\"Example file tensor: \", filenames[0])\n",
    "# print(drones)\n",
    "train_files=[]\n",
    "for path, subdirs, files in os.walk(dataset_path):\n",
    "    for name in files:\n",
    "        train_files.append(os.path.join(path, name))\n",
    "# test_file = tf.io.read_file(\n",
    "#     \"C:\\\\Users\\\\rclendening\\\\researchData\\\\Training_Data_NM_RS\\\\IF1200\\\\d301sA1r01p0120210823_6.wav\")\n",
    "# test_audio, _ = tf.audio.decode_wav(contents=test_file)\n",
    "# test_audio.shape\n",
    "\n",
    "\n",
    "def split_audio(waveData, labelName, sampleFreq):\n",
    "    '''\n",
    "    Frames audio data and converts to feature space (MFCC)\n",
    "    :param waveData: waveData array of time-domain audio\n",
    "    :param frame_duration: Duration of frames desired\n",
    "    :param startTime: Start for each clip\n",
    "    :param sampleFreq: Sample Frequency (8Khz)\n",
    "    :param labelName: Name of label\n",
    "    @return list of features (ds), list of labels corresponding to feature dataset:\n",
    "    '''\n",
    "    # middle third of data\n",
    "    duration = waveData.shape[0]\n",
    "    startTime = np.round(duration / 3)\n",
    "    endTime = np.round(duration * 2 / 3)\n",
    "    waveDataSplit= waveData[int(startTime):int(endTime)]\n",
    "    features=MFCCCalc(waveDataSplit.squeeze(), sampleFreq)\n",
    "    dataCount[droneCountDict[labelName]] += features.shape[1]\n",
    "    label= [droneDict[labelName]] * features.shape[1]\n",
    "    return features, label\n",
    "\n",
    "def create_dataset(train_files):\n",
    "    '''\n",
    "    Creates feature dataset and label dataset.\n",
    "    @param train_files: EagerTensor of file paths.\n",
    "    @return list of features (ds), list of labels corresponding to feature dataset:\n",
    "    '''\n",
    "    i = 0\n",
    "    features = []\n",
    "    labels = []\n",
    "    for x in train_files:\n",
    "        #test_file = tf.io.read_file(x)\n",
    "        #test_audio, sampleRate = tf.audio.decode_wav(contents=test_file)\n",
    "        test_audio, sampleRate = librosa.load(x, sr=8000)\n",
    "        if min(np.asarray(test_audio)) != 0:\n",
    "            x = str(x)\n",
    "            label = x.split('\\\\')\n",
    "            label = label[5]\n",
    "            newData = test_audio[0: test_audio.shape[0] - test_audio.shape[0] % sampleRate]  # trim to nearest second\n",
    "            newFeats, newLabs = split_audio(newData, label, int(sampleRate))\n",
    "            features.extend(newFeats.transpose())\n",
    "            labels.extend(newLabs)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "def MFCCCalc(audioData, Fs):\n",
    "    '''\n",
    "    Converts decoded wav file to MFCC feature space\n",
    "    @param audioData: Numpy array of decoded audio wav file\n",
    "    @return MFCC coefficients\n",
    "    '''\n",
    "    #audioData=audioData.numpy()\n",
    "    data= audioData.astype(float)\n",
    "    #coefs = mfcc(data, sr=sampleRate, hop_length=2048)\n",
    "    coefs = mfcc(y=data, hop_length=2048,n_mfcc=40, sr=Fs)\n",
    "\n",
    "    return coefs\n",
    "\n",
    "def grabTrainingSamples(n, trainingData):\n",
    "    '''\n",
    "    Ensures even training set by grabbing an even amount of training samples from each class.\n",
    "    @param n: limiting class count\n",
    "    @param trainingData: trainingData list that includes both features and labels\n",
    "    @return MFCC coefficients\n",
    "    '''\n",
    "    droneCount=0\n",
    "    noiseCount=0\n",
    "    evenTrainingData = []\n",
    "    evenLabelData = []\n",
    "    for i in range(len(labels)):\n",
    "        lab = trainingData[i][1]\n",
    "        if lab == [1, 0] and droneCount < n:\n",
    "            droneCount += 1\n",
    "            evenTrainingData.append(trainingData[i][0])\n",
    "            evenLabelData.append(lab)\n",
    "        elif lab == [0,1] and noiseCount < n:\n",
    "            noiseCount += 1\n",
    "            evenTrainingData.append(trainingData[i][0])\n",
    "            evenLabelData.append(lab)\n",
    "    return evenTrainingData, evenLabelData\n",
    "\n",
    "Fs = 8000\n",
    "numFeat = 40 #COULD BE SOURCE OF ERROR\n",
    "features, labels = create_dataset(train_files)\n",
    "newSet = list(zip(features, labels))\n",
    "random.seed(42)\n",
    "random.shuffle(newSet)  # Ensure data is mixed together\n",
    "n = np.min(dataCount)  # Ensure data is symmetric (aka even amounts of training data for all classes)\n",
    "# features, labels = grabTrainingSamples(n, features, labels)\n",
    "features, labels = grabTrainingSamples(n, newSet)\n",
    "\n",
    "trainFeatures, testFeatures, trainTruth, testTruth = train_test_split(features, labels, test_size=0.8, random_state=42)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "newLabels=[]\n",
    "for x in trainTruth: #convert one hot to actual numbers\n",
    "    if x[0] == 1:\n",
    "        val=0\n",
    "    else:\n",
    "        val=1\n",
    "    newLabels.append(val)\n",
    "newTestLabels=[]\n",
    "for x in testTruth: #convert one hot to actual numbers\n",
    "    if x[0] == 1:\n",
    "        val=0\n",
    "    else:\n",
    "        val=1\n",
    "    newTestLabels.append(val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complex Model Evaluation (Linear SVM)\n",
    "\n",
    "This function performances' linear svm with cross validation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8402173913043478\n",
      "0.8356459676835012\n"
     ]
    }
   ],
   "source": [
    "scalar= StandardScaler()\n",
    "linear_model = svm.SVC(C=0.001,kernel='linear')\n",
    "pipeline= Pipeline([('transformer', scalar), ('estimator', linear_model)])\n",
    "cv = KFold(n_splits=5)\n",
    "scores= cross_val_score(pipeline,trainFeatures,newLabels,cv=cv)\n",
    "\n",
    "print(np.average(scores))\n",
    "pipeline.fit(trainFeatures,newLabels)\n",
    "print(pipeline.score(testFeatures,newTestLabels))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complex Model Evaluation (Poly SVM)\n",
    "\n",
    "This function performances' linear svm with cross validation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scalar= StandardScaler()\n",
    "poly_model = svm.SVC(kernel='poly')\n",
    "param_grid= {\n",
    "    'estimator__C':[1,10,100], 'estimator__gamma':[1,0.1,0.001,0.0001],'estimator__degree':[2,3,4]}\n",
    "pipeline= Pipeline([('transformer', scalar), ('estimator', poly_model)])\n",
    "cv = KFold(n_splits=4)\n",
    "search = GridSearchCV(pipeline, param_grid,refit=True,verbose=3, n_jobs=-1)\n",
    "print(search.fit(trainFeatures,newLabels))\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)\n",
    "scores= cross_val_score(pipeline,trainFeatures,newLabels,cv=cv)\n",
    "print(np.average(scores))\n",
    "pipeline.fit(trainFeatures,newLabels)\n",
    "print(pipeline.score(testFeatures,newTestLabels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('transformer', StandardScaler()), ('estimator', SVC(kernel='poly'))], 'verbose': False, 'transformer': StandardScaler(), 'estimator': SVC(kernel='poly'), 'transformer__copy': True, 'transformer__with_mean': True, 'transformer__with_std': True, 'estimator__C': 1.0, 'estimator__break_ties': False, 'estimator__cache_size': 200, 'estimator__class_weight': None, 'estimator__coef0': 0.0, 'estimator__decision_function_shape': 'ovr', 'estimator__degree': 3, 'estimator__gamma': 'scale', 'estimator__kernel': 'poly', 'estimator__max_iter': -1, 'estimator__probability': False, 'estimator__random_state': None, 'estimator__shrinking': True, 'estimator__tol': 0.001, 'estimator__verbose': False}\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.get_params())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complex Model Evaluation (RBF)\n",
    "\n",
    "This function performances' hyperparameter tuning of the RBF kernel for SVM. In TS which contains 80% of data, it achieves .90073 accuracy rate."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator__C': 100, 'estimator__gamma': 0.01}\n",
      "0.9008695652173913\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9007318310267372"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar= StandardScaler()\n",
    "model = svm.SVC(kernel='rbf')\n",
    "pipeline= Pipeline([('transformer', scalar), ('estimator', model)])\n",
    "cv = KFold(n_splits=10)\n",
    "param_grid= {\n",
    "    'estimator__C':[0.1,1,10,100], 'estimator__gamma':[1,0.1,0.01,0.001,0.0001]}\n",
    "\n",
    "search = GridSearchCV(pipeline, param_grid,refit=True,verbose=3, n_jobs=-1)\n",
    "print(search.fit(trainFeatures,newLabels))\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)\n",
    "newTestLabels=[]\n",
    "for x in testTruth: #convert one hot to actual numbers\n",
    "    if x[0] == 1:\n",
    "        val=0\n",
    "    else:\n",
    "        val=1\n",
    "    newTestLabels.append(val)\n",
    "search.score(testFeatures,newTestLabels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Model Evaluation: LDA/QDA\n",
    "\n",
    "The fact that LDA outperforms QDA suggests that there is more of a linear decision boundary within the dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82753623 0.84963768 0.83188406 0.83623188 0.85072464]\n",
      "[0.77681159 0.80217391 0.77826087 0.78985507 0.78985507]\n",
      "LDA Test Set Score 0.8367690747047315\n",
      "QDA Test Set Score 0.7816281428881965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "lda= LinearDiscriminantAnalysis()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "lda.fit(trainFeatures,newLabels)\n",
    "scores= cross_val_score(lda,trainFeatures,newLabels,cv=5)\n",
    "print(scores)\n",
    "qda.fit(trainFeatures,newLabels)\n",
    "scores= cross_val_score(qda,trainFeatures,newLabels,cv=5)\n",
    "print(scores)\n",
    "print(\"LDA Test Set Score\",lda.score(testFeatures,newTestLabels))\n",
    "print(\"QDA Test Set Score\",qda.score(testFeatures,newTestLabels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "newTestTargets=[]\n",
    "for x in testTargets:\n",
    "    if x[0] == 1:\n",
    "        val=0\n",
    "    else:\n",
    "        val=1\n",
    "    newTestTargets.append(val)\n",
    "print(accuracy_score(y_true=newTestTargets, y_pred=y_pred))\n",
    "testFeats= testFeatures"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Testing with cell phone scenario. Achieving 0% accuracy because although sampled at same frequency, there must be some cell phone artifacts in the noise data that is making all cell phone data be seen as noise. After further evaluation, taking the logPSD causes the training data to potentially overfit(?). When PSD is calculated without log, the algorithm can accurately predict the drone when using cell phones as test data. Further investigation will be required to further refine and determine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This function implements majority voting scheme. It assumes all cell phones record an equal amount of data during a test, and assumes the class with the most votes is the correct class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NOISE=1\n",
    "DRONE=0\n",
    "def split_test_audio(waveData, labelName, sampleFreq):\n",
    "    '''\n",
    "    Frames audio data and converts to feature space (spectrogram)\n",
    "    :param waveData: waveData array of time-domain audio\n",
    "    :param frame_duration: Duration of frames desired\n",
    "    :param startTime: Start for each clip\n",
    "    :param sampleFreq: Sample Frequency (8Khz)\n",
    "    :param labelName: Name of label\n",
    "    @return list of features (ds), list of labels corresponding to feature dataset:\n",
    "    '''\n",
    "    duration = waveData.shape[0]\n",
    "    features=MFCCCalc(waveData.numpy().squeeze())\n",
    "    label= [droneDict[labelName]] * features.shape[1]\n",
    "    return features, label\n",
    "\n",
    "def create_test_dataset(test_files, testTime):\n",
    "    \"\"\"\n",
    "    Creates feature dataset and label dataset.\n",
    "    @param test_files: EagerTensor of file paths.\n",
    "    @return list of features (ds), list of labels corresponding to feature dataset:\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    featuresLL=[]\n",
    "    labels = []\n",
    "    numPhones=0\n",
    "    phoneName=[]\n",
    "    for x in test_files:\n",
    "        test_file = tf.io.read_file(x)\n",
    "        test_audio, sampleRate = tf.audio.decode_wav(contents=test_file)\n",
    "        if len(test_audio) >= testTime *sampleRate and min(np.asarray(test_audio)) != 0: #ensure data actually has sound and recorded correctly\n",
    "            numPhones+=1\n",
    "            x = str(x)\n",
    "            phoneName.append(x)\n",
    "            label = x.split('\\\\')\n",
    "            #label = label[6]\n",
    "            #test_audio = test_audio[0: test_audio.shape[0] - test_audio.shape[0] % 8000]  # trim to nearest second\n",
    "            test_audio = test_audio[0: (testTime-1)*sampleRate]  # trim to nearest second\n",
    "            #test_audio = test_audio[round(testTime/3)*sampleRate: round(testTime)*sampleRate]  # trim to nearest second\n",
    "            newFeats, newLabs = split_test_audio(test_audio, \"Drone\", int(sampleRate))\n",
    "            featuresLL.append(newFeats.transpose())\n",
    "            features.extend(newFeats.transpose())\n",
    "            labels.extend(newLabs)\n",
    "\n",
    "    return features, labels, numPhones, featuresLL\n",
    "\n",
    "def maxValues(features):\n",
    "    maxVals=[]\n",
    "    for x in features:\n",
    "        maxVals.append(abs(x).max())\n",
    "\n",
    "    return maxVals\n",
    "\n",
    "def maxValueRanks(maxValArray):\n",
    "    maxValueRankArr=[]\n",
    "    for x in maxValArray:\n",
    "        seq = sorted(x)\n",
    "        index = [seq.index(v) for v in x]\n",
    "        maxValueRankArr.append(index)\n",
    "    return maxValueRankArr\n",
    "def majorityVoteNew(testFeats):\n",
    "    y_prediction=[]\n",
    "    maxVals=[]\n",
    "    for x in testFeats:\n",
    "        # x -= mean\n",
    "        # x /= std\n",
    "        #x= np.reshape(x, (len(x), numFeat, 1))\n",
    "        #x_scaled= scaler.transform(x)\n",
    "        maxVals.append(maxValues(x))\n",
    "        #pred=np.argmax(trainedModel.predict(x),axis=1)\n",
    "        pred=pipeline.predict(x)\n",
    "        y_prediction.append(pred)\n",
    "\n",
    "    maxVals=np.asarray(maxVals).transpose()\n",
    "    maxValueRankArr=maxValueRanks(maxVals)\n",
    "    numPhones=len(y_prediction)\n",
    "    maxVote = (numPhones-1) * numPhones / 2 # closed form for summation\n",
    "    predictedList=[]\n",
    "    prevState=7\n",
    "    for i in range(len(pred)): # i is feature frame\n",
    "        predictedDrone=0\n",
    "        for j in range(len(y_prediction)): # j is phone\n",
    "            if y_prediction[j][i] == 0:\n",
    "            #if y_prediction[j][i] == 0 and maxValueRankArr[i][j] > 14:\n",
    "                predictedDrone+= 1*maxValueRankArr[i][j]\n",
    "                #predictedDrone+= 1\n",
    "\n",
    "        if predictedDrone/maxVote >.45:\n",
    "        #if predictedDrone/numPhones >0.63:\n",
    "        #if predictedDrone/5 >0.50:\n",
    "            predictedVal=0\n",
    "            #predictedList.append(0)\n",
    "        else:\n",
    "            #predictedList.append(1)\n",
    "            predictedVal=1\n",
    "        prevState, prediction=fourBitPrediction(prevState, predictedVal)\n",
    "        predictedList.append(prediction)\n",
    "\n",
    "    return predictedList, y_prediction\n",
    "def fourBitPrediction(prevPredictState,prediction): #prediction need to be 1 (noise) or -1 (drone)\n",
    "    if prediction == NOISE:\n",
    "        predVal=1\n",
    "    else:\n",
    "        predVal=-1\n",
    "    if prevPredictState+predVal>7:\n",
    "        actualPrediction= 1\n",
    "    else:\n",
    "        actualPrediction = 0\n",
    "    prevPredictState=prevPredictState+predVal\n",
    "    if prevPredictState>15:\n",
    "        prevPredictState=15\n",
    "    elif prevPredictState<0:\n",
    "        prevPredictState=0\n",
    "    return prevPredictState, actualPrediction\n",
    "\n",
    "def threeBitPrediction(prevPredictState,prediction): #prediction need to be 1 (noise) or -1 (drone)\n",
    "    if prediction == NOISE:\n",
    "        predVal=1\n",
    "    else:\n",
    "        predVal=-1\n",
    "    if prevPredictState+predVal>3:\n",
    "        actualPrediction= 1\n",
    "    else:\n",
    "        actualPrediction = 0\n",
    "    prevPredictState=prevPredictState+predVal\n",
    "    if prevPredictState>7:\n",
    "        prevPredictState=7\n",
    "    elif prevPredictState<0:\n",
    "        prevPredictState=0\n",
    "    return prevPredictState, actualPrediction\n",
    "\n",
    "def twoBitPrediction(prevPredictState,prediction): #prediction need to be 1 (noise) or -1 (drone)\n",
    "    if prediction == NOISE:\n",
    "        predVal=1\n",
    "    else:\n",
    "        predVal=-1\n",
    "    if prevPredictState+predVal>1:\n",
    "        actualPrediction= 1\n",
    "    else:\n",
    "        actualPrediction = 0\n",
    "    prevPredictState=prevPredictState+predVal\n",
    "    if prevPredictState>3:\n",
    "        prevPredictState=3\n",
    "    elif prevPredictState<0:\n",
    "        prevPredictState=0\n",
    "    return prevPredictState, actualPrediction\n",
    "\n",
    "\n",
    "dataset_path: str = \"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A3\\\\A3R5P2\" #TODO\n",
    "#dataset_path: str = \"C:\\\\Users\\\\rclendening\\\\researchData\\\\test123\" #TODO\n",
    "Testdata_dir = pathlib.Path(dataset_path)\n",
    "phones = tf.io.gfile.glob(str(Testdata_dir) + '/*')\n",
    "testTime= 90\n",
    "testSceneFeatures,testSceneTargets, numPhones, featuresLL =create_test_dataset(phones, testTime)\n",
    "predictedList, y_prediction = majorityVoteNew(featuresLL)\n",
    "\n",
    "correcto=0\n",
    "\n",
    "for y in y_prediction:\n",
    "    correcto=1\n",
    "    for x in range(0,348):\n",
    "        if y[x] == 0:\n",
    "            correcto+=1\n",
    "    print(\"Single Phone\",correcto/400)\n",
    "correcto=0\n",
    "for x in range(0,348):\n",
    "    if predictedList[x] == 0:\n",
    "        correcto+=1\n",
    "print(\"Accuracy for drone present:\", correcto/400)\n",
    "plt.plot(range(len(predictedList)),predictedList)\n",
    "plt.figure()\n",
    "#plt.plot(classPrediction)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correcto=0\n",
    "sumVal=0\n",
    "phone=0\n",
    "start=0\n",
    "stop=len(predictedList)\n",
    "#y_actual=[1]*200+[1]*700+[0]*1000\n",
    "y_actual=[1]*200+[0]*500+[1]*800\n",
    "for y in y_prediction:\n",
    "    phone+=1\n",
    "    correcto=0\n",
    "    for x in range(start,stop):\n",
    "        if y[x] == y_actual[x]:\n",
    "            correcto+=1\n",
    "    print(\"Single Phone\",phone)\n",
    "    print(correcto/(stop-start))\n",
    "    sumVal+= correcto/(stop-start)\n",
    "print(\"Average Value:\", sumVal/len(y_prediction))\n",
    "correcto=0\n",
    "for x in range(start,stop):\n",
    "    if predictedList[x] == y_actual[x]:\n",
    "        correcto+=1\n",
    "print(\"Accuracy for drone present:\", correcto/(stop-start))\n",
    "plt.plot(np.arange(0,testTime,testTime/len(predictedList)),predictedList)\n",
    "#plt.plot(predictedList)\n",
    "plt.figure()\n",
    "print(\"Novel method outperforms by:\", (100*((correcto/(stop-start))-sumVal/len(y_prediction))/abs(sumVal/len(y_prediction))), \"%\")\n",
    "#plt.plot(classPrediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "truthData= pd.read_csv(r\"C:\\Users\\rclendening\\researchData\\researchCSVs_Scripts_etc\\testTruthData.csv\")\n",
    "novelAve=[]\n",
    "sumAve=[]\n",
    "outPerform=[]\n",
    "for x in range(18):\n",
    "    truthScenario = truthData.iloc[x]\n",
    "    name=truthScenario[0]\n",
    "    startDetect= truthScenario[1]\n",
    "    endDetect=truthScenario[2]\n",
    "    testTime=90\n",
    "    start=0\n",
    "    dataset_path: str = \"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A3\\\\\"+name\n",
    "    Testdata_dir = pathlib.Path(dataset_path)\n",
    "    phones = tf.io.gfile.glob(str(Testdata_dir) + '/*')\n",
    "    testFeatures,testTargets, numPhones, featuresLL =create_test_dataset(phones, testTime)\n",
    "    predictedList, y_prediction = majorityVoteNew(featuresLL)\n",
    "    stop=len(predictedList)\n",
    "    y_actual=np.ones(stop)\n",
    "    y_actual[int(np.round(stop*startDetect/testTime)):int(np.round(stop*endDetect/testTime))]=0\n",
    "    sumVal=0\n",
    "    for y in y_prediction:\n",
    "        phone+=1\n",
    "        correcto=0\n",
    "        for x in range(start,stop):\n",
    "            if y[x] == y_actual[x]:\n",
    "                correcto+=1\n",
    "        #print(\"Single Phone\",phone)\n",
    "        #print(correcto/(stop-start))\n",
    "        sumVal+= correcto/(stop-start)\n",
    "    print(name)\n",
    "    print(\"Average Value:\", sumVal/len(y_prediction))\n",
    "    sumAve.append(sumVal/len(y_prediction))\n",
    "    correcto=0\n",
    "    for x in range(start,stop):\n",
    "        if predictedList[x] == y_actual[x]:\n",
    "            correcto+=1\n",
    "    percCorrect= correcto/stop\n",
    "    novelAve.append(percCorrect)\n",
    "    print(\"Accuracy for drone present:\", percCorrect)\n",
    "    #plt.plot(np.arange(0,testTime,testTime/stop),predictedList)\n",
    "#plt.plot(predictedList)\n",
    "    #plt.figure()\n",
    "    performanceGain=100*((percCorrect-sumVal/len(y_prediction))/abs(sumVal/len(y_prediction)))\n",
    "    outPerform.append(performanceGain)\n",
    "    print(\"Novel method outperforms by:\", performanceGain, \"%\")\n",
    "print(np.average(outPerform))\n",
    "print(np.average(novelAve))\n",
    "print(np.average(sumAve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "novelAve=np.asarray(novelAve)\n",
    "a_no_outliers = novelAve[(np.abs(stats.zscore(novelAve)) < 2)]\n",
    "a_no_outliers=np.sort(a_no_outliers)\n",
    "print(a_no_outliers[4:])\n",
    "print(np.average(a_no_outliers[4:]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}