{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of samples:  1051\n",
      "Number of examples per label: 381\n",
      "Example file tensor:  tf.Tensor(b'C:\\\\Users\\\\rclendening\\\\researchData\\\\RedVox_Training\\\\Matrice_600\\\\  (465).wav', shape=(), dtype=string)\n",
      "['IF1200' 'Matrice_600' 'Mavic_Pro' 'Noise' 'Phantom_4_Pro_V2']\n",
      "8660 8660\n",
      "Input shape: (61, 65, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing (Resizing)         (None, 32, 32, 1)         0         \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 32, 32, 1)        3         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1605760   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,625,224\n",
      "Trainable params: 1,625,221\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "195/195 [==============================] - 14s 70ms/step - loss: 1.3085 - accuracy: 0.4635 - val_loss: 1.1146 - val_accuracy: 0.5478\n",
      "Epoch 2/20\n",
      "195/195 [==============================] - 13s 69ms/step - loss: 1.0651 - accuracy: 0.5541 - val_loss: 0.9611 - val_accuracy: 0.5985\n",
      "Epoch 3/20\n",
      "195/195 [==============================] - 13s 69ms/step - loss: 0.9300 - accuracy: 0.6119 - val_loss: 0.8450 - val_accuracy: 0.6549\n",
      "Epoch 4/20\n",
      "195/195 [==============================] - 12s 61ms/step - loss: 0.8584 - accuracy: 0.6502 - val_loss: 0.7979 - val_accuracy: 0.6697\n",
      "Epoch 5/20\n",
      "195/195 [==============================] - 13s 66ms/step - loss: 0.7908 - accuracy: 0.6728 - val_loss: 0.7573 - val_accuracy: 0.6870\n",
      "Epoch 6/20\n",
      "195/195 [==============================] - 14s 70ms/step - loss: 0.7310 - accuracy: 0.7002 - val_loss: 0.7390 - val_accuracy: 0.6972\n",
      "Epoch 7/20\n",
      "195/195 [==============================] - 13s 67ms/step - loss: 0.6932 - accuracy: 0.7017 - val_loss: 0.7011 - val_accuracy: 0.7049\n",
      "Epoch 8/20\n",
      "195/195 [==============================] - 13s 69ms/step - loss: 0.6553 - accuracy: 0.7249 - val_loss: 0.6842 - val_accuracy: 0.7075\n",
      "Epoch 9/20\n",
      "195/195 [==============================] - 14s 72ms/step - loss: 0.6256 - accuracy: 0.7376 - val_loss: 0.6883 - val_accuracy: 0.7126\n",
      "Epoch 10/20\n",
      "195/195 [==============================] - 13s 67ms/step - loss: 0.6003 - accuracy: 0.7501 - val_loss: 0.7193 - val_accuracy: 0.7107\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from IPython import display\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "dataset_path: str = \"C:\\\\Users\\\\rclendening\\\\researchData\\\\RedVox_Training\"\n",
    "data_dir = pathlib.Path(dataset_path)\n",
    "droneDict = {  # One hot encoding for labels probs should do it like I did below?\n",
    "    \"IF1200\": [1, 0, 0, 0, 0],\n",
    "    \"Matrice_600\": [0, 1, 0, 0, 0],\n",
    "    \"Mavic_Pro\": [0, 0, 1, 0, 0],\n",
    "    \"Phantom_4_Pro_V2\": [0, 0, 0, 1, 0],\n",
    "    \"Noise\": [0, 0, 0, 0, 1]\n",
    "}\n",
    "droneCountDict = {  # One hot encoding for labels\n",
    "    \"IF1200\": 0,\n",
    "    \"Matrice_600\": 1,\n",
    "    \"Mavic_Pro\": 2,\n",
    "    \"Phantom_4_Pro_V2\": 3,\n",
    "    \"Noise\": 4\n",
    "}\n",
    "dataCount = [0, 0, 0, 0, 0]\n",
    "drones = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "num_samples = len(filenames)\n",
    "train_files = filenames\n",
    "# x = round((len(train_files) / 20))\n",
    "# train_files = train_files[:x]\n",
    "print(\"Total num of samples: \", num_samples)\n",
    "print(\"Number of examples per label:\", len(tf.io.gfile.listdir(str(data_dir / drones[0]))))\n",
    "print(\"Example file tensor: \", filenames[0])\n",
    "print(drones)\n",
    "test_file = tf.io.read_file(\n",
    "    \"C:\\\\Users\\\\rclendening\\\\researchData\\\\Training_Data_NM_RS\\\\IF1200\\\\d301sA1r01p0120210823_6.wav\")\n",
    "test_audio, _ = tf.audio.decode_wav(contents=test_file)\n",
    "test_audio.shape\n",
    "\n",
    "\n",
    "def decode_audio(audio_binary):\n",
    "    audio, _ = tf.audio.decode_wav(contents=audio_binary)\n",
    "    return tf.squeeze(audio, axis=-1)\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(input=file_path, sep=os.path.sep)\n",
    "    return parts[-2]\n",
    "\n",
    "\n",
    "def split_audio(waveData, labelName, sampleFreq, frame_duration):\n",
    "    '''\n",
    "    Frames audio data and converts to feature space (spectrogram)\n",
    "    :param waveData: waveData array of time-domain audio\n",
    "    :param frame_duration: Duration of frames desired\n",
    "    :param startTime: Start for each clip\n",
    "    :param sampleFreq: Sample Frequency (8Khz)\n",
    "    :param labelName: Name of label\n",
    "    @return list of features (ds), list of labels corresponding to feature dataset:\n",
    "    '''\n",
    "    features = []\n",
    "    label = []\n",
    "    # middle third of data\n",
    "    duration = waveData.shape[0]\n",
    "    startTime = np.round(duration / 3)\n",
    "    endTime = np.round(duration * 2 / 3)\n",
    "    frame_dur = frame_duration * sampleFreq\n",
    "    t1 = startTime\n",
    "    t2 = t1 + frame_dur\n",
    "    frame_dur = int(frame_dur)\n",
    "    t1 = int(t1)\n",
    "    t2 = int(t2)\n",
    "    if waveData.shape[0] != 0:\n",
    "        while t2 < endTime:\n",
    "            split = waveData[t1:t2]\n",
    "            t1 = t2\n",
    "            t2 = t2 + frame_dur\n",
    "            split = tf.reshape(split, frame_dur)\n",
    "            split = get_spectrogram(split, frame_dur)\n",
    "            features.append(split)\n",
    "            # label.append(labelName)\n",
    "            dataCount[droneCountDict[labelName]] += 1\n",
    "            label.append(droneDict[labelName])  # one hot encoding\n",
    "    return features, label\n",
    "\n",
    "def split_test_audio(waveData, labelName, sampleFreq, frame_duration):\n",
    "    '''\n",
    "    Frames audio data and converts to feature space (spectrogram)\n",
    "    :param waveData: waveData array of time-domain audio\n",
    "    :param frame_duration: Duration of frames desired (in seconds)\n",
    "    :param startTime: Start for each clip\n",
    "    :param sampleFreq: Sample Frequency (8Khz)\n",
    "    :param labelName: Name of label\n",
    "    @return list of features (ds), list of labels corresponding to feature dataset:\n",
    "    '''\n",
    "    features = []\n",
    "    label = []\n",
    "    # middle third of data\n",
    "    duration = waveData.shape[0]\n",
    "    startTime = 0\n",
    "    endTime = startTime+duration\n",
    "    frame_dur = frame_duration * sampleFreq\n",
    "    t1 = startTime\n",
    "    t2 = t1 + frame_dur\n",
    "    frame_dur = int(round(frame_dur))\n",
    "    t1 = int(t1)\n",
    "    t2 = int(t2)\n",
    "    if waveData.shape[0] != 0:\n",
    "        while t2 < endTime:\n",
    "            split = waveData[t1:t2]\n",
    "            t1 = t2\n",
    "            t2 = t2 + frame_dur\n",
    "            split = tf.reshape(split, frame_dur)\n",
    "            split = get_spectrogram(split, frame_dur)\n",
    "            features.append(split)\n",
    "            # label.append(labelName)\n",
    "            label.append(labelName)  # one hot encoding\n",
    "    return features, label\n",
    "\n",
    "def create_dataset(train_files):\n",
    "    '''\n",
    "    Creates feature dataset and label dataset.\n",
    "    @param train_files: EagerTensor of file paths.\n",
    "    @return list of features (ds), list of labels corresponding to feature dataset:\n",
    "    '''\n",
    "    i = 0\n",
    "    features = []\n",
    "    labels = []\n",
    "    for x in train_files:\n",
    "        test_file = tf.io.read_file(x)\n",
    "        test_audio, sampleRate = tf.audio.decode_wav(contents=test_file)\n",
    "        x = str(x)\n",
    "        label = x.split('\\\\')\n",
    "        label = label[10]\n",
    "        test_audio = test_audio[0: test_audio.shape[0] - test_audio.shape[0] % 8000]  # trim to nearest second\n",
    "        newFeats, newLabs = split_audio(test_audio, label, int(sampleRate), 0.5)\n",
    "        features.extend(newFeats)\n",
    "        labels.extend(newLabs)\n",
    "        i = i + 1\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "def create_test_dataset(test_files):\n",
    "    '''\n",
    "    Creates feature dataset and label dataset.\n",
    "    @param test_files: EagerTensor of file paths.\n",
    "    @return list of features (ds), list of labels corresponding to feature dataset:\n",
    "    '''\n",
    "    i = 0\n",
    "    features = []\n",
    "    labels = []\n",
    "    for x in test_files:\n",
    "        test_file = tf.io.read_file(x)\n",
    "        test_audio, sampleRate = tf.audio.decode_wav(contents=test_file)\n",
    "        x = str(x)\n",
    "        label = x.split('\\\\')\n",
    "        label = label[6]\n",
    "        test_audio = test_audio[0: test_audio.shape[0] - test_audio.shape[0] % 8000]  # trim to nearest second\n",
    "        newFeats, newLabs = split_test_audio(test_audio, label, int(sampleRate), 0.10)\n",
    "        features.extend(newFeats)\n",
    "        labels.extend(newLabs)\n",
    "        i = i + 1\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "def get_waveform_and_label(file_path):\n",
    "    label = get_label(file_path)\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform = decode_audio(audio_binary)\n",
    "    return waveform, label\n",
    "\n",
    "\n",
    "def get_spectrogram(waveform, length):\n",
    "    # Zero-padding for an audio waveform with less than length samples\n",
    "    input_len = length\n",
    "    waveform = waveform[:input_len]\n",
    "    zero_padding = tf.zeros(\n",
    "        [length] - tf.shape(waveform),\n",
    "        dtype=tf.float32)\n",
    "    # Cast the waveform tensors' dtype to float32.\n",
    "    waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "    # Concatenate the waveform with `zero_padding`, which ensures all audio\n",
    "    # clips are of the same length.\n",
    "    equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "    # Convert the waveform to a spectrogram via a STFT.\n",
    "    spectrogram = tf.signal.stft(\n",
    "        equal_length, frame_length=128, frame_step=64)\n",
    "    # Obtain the magnitude of the STFT.\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    # Add a `channels` dimension, so that the spectrogram can be used\n",
    "    # as image-like input data with convolution layers (which expect\n",
    "    # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "    spectrogram = spectrogram[..., tf.newaxis]\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "def grabTrainingSamples(n, trainingData):\n",
    "    IFCount = 0\n",
    "    matriceCount = 0\n",
    "    phantomCount = 0\n",
    "    mavicCount = 0\n",
    "    noiseCount = 0\n",
    "    evenTrainingData = []\n",
    "    evenLabelData = []\n",
    "    for i in range(len(labels)):\n",
    "        lab = trainingData[i][1]\n",
    "        if lab == [1, 0, 0, 0, 0] and IFCount < n:\n",
    "            IFCount += 1\n",
    "            evenTrainingData.append(trainingData[i][0])\n",
    "            evenLabelData.append(lab)\n",
    "        elif lab == [0, 1, 0, 0, 0] and matriceCount < n:\n",
    "            matriceCount += 1\n",
    "            evenTrainingData.append(trainingData[i][0])\n",
    "            evenLabelData.append(lab)\n",
    "        elif lab == [0, 0, 1, 0, 0] and phantomCount < n:\n",
    "            phantomCount += 1\n",
    "            evenTrainingData.append(trainingData[i][0])\n",
    "            evenLabelData.append(lab)\n",
    "        elif lab == [0, 0, 0, 1, 0] and mavicCount < n:\n",
    "            mavicCount += 1\n",
    "            evenTrainingData.append(trainingData[i][0])\n",
    "            evenLabelData.append(lab)\n",
    "        elif lab == [0, 0, 0, 0, 1] and noiseCount < n:\n",
    "            noiseCount += 1\n",
    "            evenTrainingData.append(trainingData[i][0])\n",
    "            evenLabelData.append(lab)\n",
    "    return evenTrainingData, evenLabelData\n",
    "\n",
    "# testFeatures,testTargets =create_test_dataset([\"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A1\\\\A1R1P1\\\\Phone_1-3.wav\",\"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A1\\\\A1R2P1\\\\Phone_5-2.wav\"])\n",
    "#\n",
    "# # TODO: Finish creating custom test data\n",
    "# for x in range(len(testTargets)):\n",
    "#     if testTargets[x] == \"A1R1P1\":\n",
    "#         testTargets[x] = [1, 0, 0, 0, 0]\n",
    "#     elif testTargets[x] == \"A1R2P1\":\n",
    "#         testTargets[x] = [0, 1, 0, 0, 0]\n",
    "###\n",
    "features, labels = create_dataset(train_files)\n",
    "newSet = list(zip(features, labels))\n",
    "random.seed()\n",
    "random.shuffle(newSet)  # Ensure data is mixed together\n",
    "n = np.min(dataCount)  # Ensure data is symmetric (aka even amounts of training data for all classes)\n",
    "# features, labels = grabTrainingSamples(n, features, labels)\n",
    "features, labels = grabTrainingSamples(n, newSet)\n",
    "print(len(features), len(labels))\n",
    "\n",
    "trainFeatures, testFeatures, trainTargets, testTargets = train_test_split(features, labels, test_size=0.10,\n",
    "                                                                          random_state=42)\n",
    "\n",
    "\n",
    "# trainFeatures = np.asarray(trainFeatures)\n",
    "# trainTargets = np.asarray(trainTargets)\n",
    "# mean = trainFeatures.mean(axis=0)\n",
    "# trainFeatures -= mean\n",
    "# std = trainFeatures.std(axis=0)\n",
    "# trainFeatures /= std\n",
    "# trainFeatures = np.reshape(trainFeatures,\n",
    "#                             (len(trainFeatures), trainFeatures.shape[1:], 1))\n",
    "# trainFeatures = np.squeeze(trainFeatures)\n",
    "# testFeatures = np.asarray(testFeatures)\n",
    "# testTargets = np.asarray(testTargets)\n",
    "# testFeatures -= mean\n",
    "# testFeatures /= std\n",
    "# testFeatures = np.reshape(testFeatures, (len(testFeatures), numFeat, 1))\n",
    "# testFeatures = np.squeeze(testFeatures)\n",
    "trainFeatures=tf.convert_to_tensor(trainFeatures)\n",
    "testFeatures=tf.convert_to_tensor(testFeatures)\n",
    "norm_layer = tf.keras.layers.Normalization()\n",
    "#norm_layer.adapt(np.squeeze(trainFeatures))\n",
    "norm_layer.adapt(trainFeatures)\n",
    "\n",
    "print('Input shape:', np.shape(trainFeatures)[1:])\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=np.shape(trainFeatures)[1:]),\n",
    "    # Downsample the input.\n",
    "    layers.Resizing(32, 32),\n",
    "    # Normalize.\n",
    "    norm_layer,\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(dataCount)),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "EPOCHS = 20\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                 verbose=1, patience=10, mode='auto')\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4,\n",
    "                          patience=40, mode='auto')\n",
    "trainFeatures=np.asarray(trainFeatures)\n",
    "trainTargets=np.asarray(trainTargets)\n",
    "#trainTargets=tf.convert_to_tensor(trainTargets)\n",
    "history = model.fit(\n",
    "    trainFeatures,\n",
    "    trainTargets,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.2,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.7448036951501155\n"
     ]
    }
   ],
   "source": [
    "# testFeatures,testTargets =create_test_dataset([\"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A1\\\\A1R1P2\\\\Phone_1-3.wav\",\"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A1\\\\A1R1P2\\\\Phone_5-2.wav\",\"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A1\\\\A1R1P2\\\\Phone_5-3.wav\",\n",
    "#                                                \"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A1\\\\A1R1P2\\\\Phone_6-2.wav\",\n",
    "#                                                \"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A1\\\\A1R1P2\\\\Phone_7-2.wav\",\n",
    "#                                                \"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A1\\\\A1R1P2\\\\Phone_5-2.wav\",\n",
    "#                                                \"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A1\\\\A1R1P2\\\\Phone_1-1.wav\",\n",
    "#                                                \"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A1\\\\A1R1P2\\\\Phone_2-4.wav\",\n",
    "#                                                #\"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A1\\\\A1R1P1\\\\Phone_3-1.wav\", distorted AF\n",
    "#                                                \"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A1\\\\A1R1P2\\\\Phone_8.wav\",\n",
    "#                                                \"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A1\\\\A1R1P2\\\\Phone_29.wav\",\n",
    "#                                                \"C:\\\\Users\\\\rclendening\\\\researchData\\\\EscapeCell_DataWav\\\\A1\\\\A1R1P2\\\\Phone_30.wav\"])\n",
    "#\n",
    "# # TODO: Finish creating custom test data\n",
    "# for x in range(len(testTargets)):\n",
    "#     if testTargets[x] == \"A1R1P2\":\n",
    "#         testTargets[x] = [1, 0, 0, 0, 0]\n",
    "#     elif testTargets[x] == \"A1R2P1\":\n",
    "#         testTargets[x] = [0, 1, 0, 0, 0]\n",
    "# testFeatures= tf.convert_to_tensor(testFeatures)\n",
    "#testTargets= tf.convert_to_tensor(testTargets)\n",
    "y_pred = np.argmax(model.predict(testFeatures), axis=1)\n",
    "y_predict=[]\n",
    "for x in y_pred:\n",
    "    ans=np.zeros(5)\n",
    "    ans[x]=1\n",
    "    y_predict.append(ans)\n",
    "y_true = testTargets\n",
    "Sum=0\n",
    "for x in range(len(y_predict)):\n",
    "    if y_predict[x].tolist()==y_true[x]:\n",
    "        Sum+=1\n",
    "Matrice=0\n",
    "IF=0\n",
    "Noise=0\n",
    "Mavic=0\n",
    "Phantom=0\n",
    "for x in range(len(y_predict)):\n",
    "    if y_predict[x].tolist()==[1,0,0,0,0]:\n",
    "        IF+=1\n",
    "    if y_predict[x].tolist()==[0,1,0,0,0]:\n",
    "        Matrice+=1\n",
    "    if y_predict[x].tolist()==[0,0,1,0,0]:\n",
    "        Mavic+=1\n",
    "    if y_predict[x].tolist()==[0,0,0,1,0]:\n",
    "        Phantom+=1\n",
    "    if y_predict[x].tolist()==[0,0,0,0,1]:\n",
    "        Noise+=1\n",
    "#Sum=sum(y_predict == y_true)\n",
    "#list=[IF,Matrice,Mavic,Noise,Phantom]\n",
    "#print(np.max(list))\n",
    "test_acc = Sum/ len(y_true)\n",
    "print(f'Test set accuracy:', test_acc)\n",
    "    #callbacks=[reduceLR, early])\n",
    "    #callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}